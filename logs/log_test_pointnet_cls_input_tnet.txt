I0601 08:31:49.914399  5268 caffe.cpp:266] Use GPU with device ID 0
I0601 08:31:49.962270  5268 caffe.cpp:270] GPU device name: Tesla K40c
I0601 08:31:50.171316  5268 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0601 08:31:50.171730  5268 net.cpp:51] Initializing net from parameters: 
name: "pointnet_cls_basic"
state {
  phase: TEST
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "data/modelnet40_ply_hdf5_2048/test_files.txt"
    batch_size: 32
  }
}
layer {
  name: "reshape"
  type: "Reshape"
  bottom: "data"
  top: "data_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: -1
      dim: 3
    }
  }
}
layer {
  name: "conv1_tnet1"
  type: "Convolution"
  bottom: "data_reshape"
  top: "conv1_tnet1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    kernel_h: 1
    kernel_w: 3
  }
}
layer {
  name: "bn1_tnet1"
  type: "BatchNorm"
  bottom: "conv1_tnet1"
  top: "bn1_tnet1"
}
layer {
  name: "scale1_tnet1"
  type: "Scale"
  bottom: "bn1_tnet1"
  top: "scale1_tnet1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_tnet1"
  type: "ReLU"
  bottom: "scale1_tnet1"
  top: "scale1_tnet1"
}
layer {
  name: "conv2_tnet1"
  type: "Convolution"
  bottom: "scale1_tnet1"
  top: "conv2_tnet1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 128
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    kernel_h: 1
    kernel_w: 1
  }
}
layer {
  name: "bn2_tnet1"
  type: "BatchNorm"
  bottom: "conv2_tnet1"
  top: "bn2_tnet1"
}
layer {
  name: "scale2_tnet1"
  type: "Scale"
  bottom: "bn2_tnet1"
  top: "scale2_tnet1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_tnet1"
  type: "ReLU"
  bottom: "scale2_tnet1"
  top: "scale2_tnet1"
}
layer {
  name: "conv3_tnet1"
  type: "Convolution"
  bottom: "scale2_tnet1"
  top: "conv3_tnet1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 1024
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    kernel_h: 1
    kernel_w: 1
  }
}
layer {
  name: "bn3_tnet1"
  type: "BatchNorm"
  bottom: "conv3_tnet1"
  top: "bn3_tnet1"
}
layer {
  name: "scale3_tnet1"
  type: "Scale"
  bottom: "bn3_tnet1"
  top: "scale3_tnet1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3_tnet1"
  type: "ReLU"
  bottom: "scale3_tnet1"
  top: "scale3_tnet1"
}
layer {
  name: "pool_tnet1"
  type: "Pooling"
  bottom: "scale3_tnet1"
  top: "global_feat_tnet1"
  pooling_param {
    pool: MAX
    stride: 1
    pad: 0
    kernel_h: 2048
    kernel_w: 1
  }
}
layer {
  name: "fc1_tnet1"
  type: "InnerProduct"
  bottom: "global_feat_tnet1"
  top: "fc1_tnet1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn6_tnet1"
  type: "BatchNorm"
  bottom: "fc1_tnet1"
  top: "bn6_tnet1"
}
layer {
  name: "scale6_tnet1"
  type: "Scale"
  bottom: "bn6_tnet1"
  top: "scale6_tnet1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu6_tnet1"
  type: "ReLU"
  bottom: "scale6_tnet1"
  top: "scale6_tnet1"
}
layer {
  name: "fc2_tnet1"
  type: "InnerProduct"
  bottom: "scale6_tnet1"
  top: "fc2_tnet1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn7_tnet1"
  type: "BatchNorm"
  bottom: "fc2_tnet1"
  top: "bn7_tnet1"
}
layer {
  name: "scale7_tnet1"
  type: "Scale"
  bottom: "bn7_tnet1"
  top: "scale7_tnet1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu7_tnet1"
  type: "ReLU"
  bottom: "scale7_tnet1"
  top: "scale7_tnet1"
}
layer {
  name: "fc3_tnet1"
  type: "InnerProduct"
  bottom: "scale7_tnet1"
  top: "fc3_tnet1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  inner_product_param {
    num_output: 9
    weight_filler {
      type: "constant"
      value: 0
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "reshape_tnet1"
  type: "Reshape"
  bottom: "fc3_tnet1"
  top: "fc3_tnet1_reshape"
  reshape_param {
    shape {
      dim: -1
      dim: 3
      dim: 3
    }
  }
}
layer {
  name: "eye_tnet1"
  type: "Python"
  bottom: "fc3_tnet1"
  top: "eye_tnet1"
  python_param {
    module: "eye_matrix_layer"
    layer: "EyeMatrixLayer"
    param_str: "{\'K\': 3}"
  }
}
layer {
  name: "eltwise_sum_tnet1"
  type: "Eltwise"
  bottom: "fc3_tnet1_reshape"
  bottom: "eye_tnet1"
  top: "transform1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "matmul_input"
  type: "MatrixMultiplication"
  bottom: "data"
  bottom: "transform1"
  top: "data_transform1"
}
layer {
  name: "reshape"
  type: "Reshape"
  bottom: "data_transform1"
  top: "data_transform1_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: -1
      dim: 3
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data_transform1_reshape"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    kernel_h: 1
    kernel_w: 3
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "bn1"
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "bn1"
  top: "scale1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "scale1"
  top: "scale1"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "scale1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    kernel_h: 1
    kernel_w: 1
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "bn2"
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "bn2"
  top: "scale2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "scale2"
  top: "scale2"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "scale2"
  top: "conv3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    kernel_h: 1
    kernel_w: 1
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "bn3"
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "bn3"
  top: "scale3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "scale3"
  top: "scale3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "scale3"
  top: "conv4"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 128
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    kernel_h: 1
    kernel_w: 1
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "bn4"
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "bn4"
  top: "scale4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "scale4"
  top: "scale4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "scale4"
  top: "conv5"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 1024
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    kernel_h: 1
    kernel_w: 1
  }
}
layer {
  name: "bn5"
  type: "BatchNorm"
  bottom: "conv5"
  top: "bn5"
}
layer {
  name: "scale5"
  type: "Scale"
  bottom: "bn5"
  top: "scale5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "scale5"
  top: "scale5"
}
layer {
  name: "pool"
  type: "Pooling"
  bottom: "scale5"
  top: "global_feat"
  pooling_param {
    pool: MAX
    stride: 1
    pad: 0
    kernel_h: 2048
    kernel_w: 1
  }
}
layer {
  name: "fc1"
  type: "InnerProduct"
  bottom: "global_feat"
  top: "fc1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn6"
  type: "BatchNorm"
  bottom: "fc1"
  top: "bn6"
}
layer {
  name: "scale6"
  type: "Scale"
  bottom: "bn6"
  top: "scale6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "scale6"
  top: "scale6"
}
layer {
  name: "fc2"
  type: "InnerProduct"
  bottom: "scale6"
  top: "fc2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn7"
  type: "BatchNorm"
  bottom: "fc2"
  top: "bn7"
}
layer {
  name: "scale7"
  type: "Scale"
  bottom: "bn7"
  top: "scale7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "scale7"
  top: "scale7"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "scale7"
  top: "drop1"
  dropout_param {
    dropout_ratio: 0.3
  }
}
layer {
  name: "fc3"
  type: "InnerProduct"
  bottom: "drop1"
  top: "fc3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  inner_product_param {
    num_output: 40
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc3"
  bottom: "label"
  top: "loss"
}
I0601 08:31:50.172056  5268 layer_factory.hpp:77] Creating layer data
I0601 08:31:50.172075  5268 net.cpp:84] Creating Layer data
I0601 08:31:50.172083  5268 net.cpp:380] data -> data
I0601 08:31:50.172111  5268 net.cpp:380] data -> label
I0601 08:31:50.172122  5268 hdf5_data_layer.cpp:80] Loading list of HDF5 filenames from: data/modelnet40_ply_hdf5_2048/test_files.txt
I0601 08:31:50.172165  5268 hdf5_data_layer.cpp:94] Number of HDF5 files: 2
I0601 08:31:50.173133  5268 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0601 08:31:50.529459  5268 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0601 08:31:50.530395  5268 net.cpp:122] Setting up data
I0601 08:31:50.530413  5268 net.cpp:129] Top shape: 32 2048 3 (196608)
I0601 08:31:50.530418  5268 net.cpp:129] Top shape: 32 1 (32)
I0601 08:31:50.530421  5268 net.cpp:137] Memory required for data: 786560
I0601 08:31:50.530428  5268 layer_factory.hpp:77] Creating layer data_data_0_split
I0601 08:31:50.530441  5268 net.cpp:84] Creating Layer data_data_0_split
I0601 08:31:50.530450  5268 net.cpp:406] data_data_0_split <- data
I0601 08:31:50.530467  5268 net.cpp:380] data_data_0_split -> data_data_0_split_0
I0601 08:31:50.530480  5268 net.cpp:380] data_data_0_split -> data_data_0_split_1
I0601 08:31:50.530519  5268 net.cpp:122] Setting up data_data_0_split
I0601 08:31:50.530529  5268 net.cpp:129] Top shape: 32 2048 3 (196608)
I0601 08:31:50.530534  5268 net.cpp:129] Top shape: 32 2048 3 (196608)
I0601 08:31:50.530539  5268 net.cpp:137] Memory required for data: 2359424
I0601 08:31:50.530566  5268 layer_factory.hpp:77] Creating layer label_data_1_split
I0601 08:31:50.530576  5268 net.cpp:84] Creating Layer label_data_1_split
I0601 08:31:50.530582  5268 net.cpp:406] label_data_1_split <- label
I0601 08:31:50.530591  5268 net.cpp:380] label_data_1_split -> label_data_1_split_0
I0601 08:31:50.530601  5268 net.cpp:380] label_data_1_split -> label_data_1_split_1
I0601 08:31:50.530635  5268 net.cpp:122] Setting up label_data_1_split
I0601 08:31:50.530644  5268 net.cpp:129] Top shape: 32 1 (32)
I0601 08:31:50.530652  5268 net.cpp:129] Top shape: 32 1 (32)
I0601 08:31:50.530658  5268 net.cpp:137] Memory required for data: 2359680
I0601 08:31:50.530663  5268 layer_factory.hpp:77] Creating layer reshape
I0601 08:31:50.530674  5268 net.cpp:84] Creating Layer reshape
I0601 08:31:50.530680  5268 net.cpp:406] reshape <- data_data_0_split_0
I0601 08:31:50.530689  5268 net.cpp:380] reshape -> data_reshape
I0601 08:31:50.530722  5268 net.cpp:122] Setting up reshape
I0601 08:31:50.530732  5268 net.cpp:129] Top shape: 32 1 2048 3 (196608)
I0601 08:31:50.530737  5268 net.cpp:137] Memory required for data: 3146112
I0601 08:31:50.530743  5268 layer_factory.hpp:77] Creating layer conv1_tnet1
I0601 08:31:50.530763  5268 net.cpp:84] Creating Layer conv1_tnet1
I0601 08:31:50.530771  5268 net.cpp:406] conv1_tnet1 <- data_reshape
I0601 08:31:50.530779  5268 net.cpp:380] conv1_tnet1 -> conv1_tnet1
I0601 08:31:50.802994  5268 net.cpp:122] Setting up conv1_tnet1
I0601 08:31:50.803027  5268 net.cpp:129] Top shape: 32 64 2048 1 (4194304)
I0601 08:31:50.803031  5268 net.cpp:137] Memory required for data: 19923328
I0601 08:31:50.803050  5268 layer_factory.hpp:77] Creating layer bn1_tnet1
I0601 08:31:50.803061  5268 net.cpp:84] Creating Layer bn1_tnet1
I0601 08:31:50.803068  5268 net.cpp:406] bn1_tnet1 <- conv1_tnet1
I0601 08:31:50.803077  5268 net.cpp:380] bn1_tnet1 -> bn1_tnet1
I0601 08:31:50.803292  5268 net.cpp:122] Setting up bn1_tnet1
I0601 08:31:50.803304  5268 net.cpp:129] Top shape: 32 64 2048 1 (4194304)
I0601 08:31:50.803310  5268 net.cpp:137] Memory required for data: 36700544
I0601 08:31:50.803324  5268 layer_factory.hpp:77] Creating layer scale1_tnet1
I0601 08:31:50.803335  5268 net.cpp:84] Creating Layer scale1_tnet1
I0601 08:31:50.803341  5268 net.cpp:406] scale1_tnet1 <- bn1_tnet1
I0601 08:31:50.803349  5268 net.cpp:380] scale1_tnet1 -> scale1_tnet1
I0601 08:31:50.803401  5268 layer_factory.hpp:77] Creating layer scale1_tnet1
I0601 08:31:50.803520  5268 net.cpp:122] Setting up scale1_tnet1
I0601 08:31:50.803530  5268 net.cpp:129] Top shape: 32 64 2048 1 (4194304)
I0601 08:31:50.803536  5268 net.cpp:137] Memory required for data: 53477760
I0601 08:31:50.803545  5268 layer_factory.hpp:77] Creating layer relu1_tnet1
I0601 08:31:50.803555  5268 net.cpp:84] Creating Layer relu1_tnet1
I0601 08:31:50.803561  5268 net.cpp:406] relu1_tnet1 <- scale1_tnet1
I0601 08:31:50.803570  5268 net.cpp:367] relu1_tnet1 -> scale1_tnet1 (in-place)
I0601 08:31:50.803987  5268 net.cpp:122] Setting up relu1_tnet1
I0601 08:31:50.804002  5268 net.cpp:129] Top shape: 32 64 2048 1 (4194304)
I0601 08:31:50.804008  5268 net.cpp:137] Memory required for data: 70254976
I0601 08:31:50.804014  5268 layer_factory.hpp:77] Creating layer conv2_tnet1
I0601 08:31:50.804033  5268 net.cpp:84] Creating Layer conv2_tnet1
I0601 08:31:50.804040  5268 net.cpp:406] conv2_tnet1 <- scale1_tnet1
I0601 08:31:50.804050  5268 net.cpp:380] conv2_tnet1 -> conv2_tnet1
I0601 08:31:50.805779  5268 net.cpp:122] Setting up conv2_tnet1
I0601 08:31:50.805814  5268 net.cpp:129] Top shape: 32 128 2048 1 (8388608)
I0601 08:31:50.805817  5268 net.cpp:137] Memory required for data: 103809408
I0601 08:31:50.805832  5268 layer_factory.hpp:77] Creating layer bn2_tnet1
I0601 08:31:50.805845  5268 net.cpp:84] Creating Layer bn2_tnet1
I0601 08:31:50.805850  5268 net.cpp:406] bn2_tnet1 <- conv2_tnet1
I0601 08:31:50.805860  5268 net.cpp:380] bn2_tnet1 -> bn2_tnet1
I0601 08:31:50.806077  5268 net.cpp:122] Setting up bn2_tnet1
I0601 08:31:50.806111  5268 net.cpp:129] Top shape: 32 128 2048 1 (8388608)
I0601 08:31:50.806119  5268 net.cpp:137] Memory required for data: 137363840
I0601 08:31:50.806130  5268 layer_factory.hpp:77] Creating layer scale2_tnet1
I0601 08:31:50.806140  5268 net.cpp:84] Creating Layer scale2_tnet1
I0601 08:31:50.806145  5268 net.cpp:406] scale2_tnet1 <- bn2_tnet1
I0601 08:31:50.806154  5268 net.cpp:380] scale2_tnet1 -> scale2_tnet1
I0601 08:31:50.806203  5268 layer_factory.hpp:77] Creating layer scale2_tnet1
I0601 08:31:50.806316  5268 net.cpp:122] Setting up scale2_tnet1
I0601 08:31:50.806326  5268 net.cpp:129] Top shape: 32 128 2048 1 (8388608)
I0601 08:31:50.806331  5268 net.cpp:137] Memory required for data: 170918272
I0601 08:31:50.806340  5268 layer_factory.hpp:77] Creating layer relu2_tnet1
I0601 08:31:50.806349  5268 net.cpp:84] Creating Layer relu2_tnet1
I0601 08:31:50.806354  5268 net.cpp:406] relu2_tnet1 <- scale2_tnet1
I0601 08:31:50.806361  5268 net.cpp:367] relu2_tnet1 -> scale2_tnet1 (in-place)
I0601 08:31:50.806620  5268 net.cpp:122] Setting up relu2_tnet1
I0601 08:31:50.806634  5268 net.cpp:129] Top shape: 32 128 2048 1 (8388608)
I0601 08:31:50.806639  5268 net.cpp:137] Memory required for data: 204472704
I0601 08:31:50.806645  5268 layer_factory.hpp:77] Creating layer conv3_tnet1
I0601 08:31:50.806660  5268 net.cpp:84] Creating Layer conv3_tnet1
I0601 08:31:50.806668  5268 net.cpp:406] conv3_tnet1 <- scale2_tnet1
I0601 08:31:50.806675  5268 net.cpp:380] conv3_tnet1 -> conv3_tnet1
I0601 08:31:50.809741  5268 net.cpp:122] Setting up conv3_tnet1
I0601 08:31:50.809764  5268 net.cpp:129] Top shape: 32 1024 2048 1 (67108864)
I0601 08:31:50.809768  5268 net.cpp:137] Memory required for data: 472908160
I0601 08:31:50.809777  5268 layer_factory.hpp:77] Creating layer bn3_tnet1
I0601 08:31:50.809785  5268 net.cpp:84] Creating Layer bn3_tnet1
I0601 08:31:50.809792  5268 net.cpp:406] bn3_tnet1 <- conv3_tnet1
I0601 08:31:50.809800  5268 net.cpp:380] bn3_tnet1 -> bn3_tnet1
I0601 08:31:50.810019  5268 net.cpp:122] Setting up bn3_tnet1
I0601 08:31:50.810032  5268 net.cpp:129] Top shape: 32 1024 2048 1 (67108864)
I0601 08:31:50.810039  5268 net.cpp:137] Memory required for data: 741343616
I0601 08:31:50.810053  5268 layer_factory.hpp:77] Creating layer scale3_tnet1
I0601 08:31:50.810062  5268 net.cpp:84] Creating Layer scale3_tnet1
I0601 08:31:50.810067  5268 net.cpp:406] scale3_tnet1 <- bn3_tnet1
I0601 08:31:50.810075  5268 net.cpp:380] scale3_tnet1 -> scale3_tnet1
I0601 08:31:50.810120  5268 layer_factory.hpp:77] Creating layer scale3_tnet1
I0601 08:31:50.810240  5268 net.cpp:122] Setting up scale3_tnet1
I0601 08:31:50.810250  5268 net.cpp:129] Top shape: 32 1024 2048 1 (67108864)
I0601 08:31:50.810256  5268 net.cpp:137] Memory required for data: 1009779072
I0601 08:31:50.810264  5268 layer_factory.hpp:77] Creating layer relu3_tnet1
I0601 08:31:50.810273  5268 net.cpp:84] Creating Layer relu3_tnet1
I0601 08:31:50.810279  5268 net.cpp:406] relu3_tnet1 <- scale3_tnet1
I0601 08:31:50.810288  5268 net.cpp:367] relu3_tnet1 -> scale3_tnet1 (in-place)
I0601 08:31:50.810672  5268 net.cpp:122] Setting up relu3_tnet1
I0601 08:31:50.810688  5268 net.cpp:129] Top shape: 32 1024 2048 1 (67108864)
I0601 08:31:50.810693  5268 net.cpp:137] Memory required for data: 1278214528
I0601 08:31:50.810699  5268 layer_factory.hpp:77] Creating layer pool_tnet1
I0601 08:31:50.810712  5268 net.cpp:84] Creating Layer pool_tnet1
I0601 08:31:50.810719  5268 net.cpp:406] pool_tnet1 <- scale3_tnet1
I0601 08:31:50.810729  5268 net.cpp:380] pool_tnet1 -> global_feat_tnet1
I0601 08:31:50.810788  5268 net.cpp:122] Setting up pool_tnet1
I0601 08:31:50.810798  5268 net.cpp:129] Top shape: 32 1024 1 1 (32768)
I0601 08:31:50.810804  5268 net.cpp:137] Memory required for data: 1278345600
I0601 08:31:50.810811  5268 layer_factory.hpp:77] Creating layer fc1_tnet1
I0601 08:31:50.810823  5268 net.cpp:84] Creating Layer fc1_tnet1
I0601 08:31:50.810830  5268 net.cpp:406] fc1_tnet1 <- global_feat_tnet1
I0601 08:31:50.810838  5268 net.cpp:380] fc1_tnet1 -> fc1_tnet1
I0601 08:31:50.823282  5268 net.cpp:122] Setting up fc1_tnet1
I0601 08:31:50.823324  5268 net.cpp:129] Top shape: 32 512 (16384)
I0601 08:31:50.823329  5268 net.cpp:137] Memory required for data: 1278411136
I0601 08:31:50.823343  5268 layer_factory.hpp:77] Creating layer bn6_tnet1
I0601 08:31:50.823355  5268 net.cpp:84] Creating Layer bn6_tnet1
I0601 08:31:50.823361  5268 net.cpp:406] bn6_tnet1 <- fc1_tnet1
I0601 08:31:50.823375  5268 net.cpp:380] bn6_tnet1 -> bn6_tnet1
I0601 08:31:50.823597  5268 net.cpp:122] Setting up bn6_tnet1
I0601 08:31:50.823609  5268 net.cpp:129] Top shape: 32 512 (16384)
I0601 08:31:50.823614  5268 net.cpp:137] Memory required for data: 1278476672
I0601 08:31:50.823624  5268 layer_factory.hpp:77] Creating layer scale6_tnet1
I0601 08:31:50.823633  5268 net.cpp:84] Creating Layer scale6_tnet1
I0601 08:31:50.823639  5268 net.cpp:406] scale6_tnet1 <- bn6_tnet1
I0601 08:31:50.823647  5268 net.cpp:380] scale6_tnet1 -> scale6_tnet1
I0601 08:31:50.823691  5268 layer_factory.hpp:77] Creating layer scale6_tnet1
I0601 08:31:50.823809  5268 net.cpp:122] Setting up scale6_tnet1
I0601 08:31:50.823819  5268 net.cpp:129] Top shape: 32 512 (16384)
I0601 08:31:50.823824  5268 net.cpp:137] Memory required for data: 1278542208
I0601 08:31:50.823833  5268 layer_factory.hpp:77] Creating layer relu6_tnet1
I0601 08:31:50.823842  5268 net.cpp:84] Creating Layer relu6_tnet1
I0601 08:31:50.823846  5268 net.cpp:406] relu6_tnet1 <- scale6_tnet1
I0601 08:31:50.823853  5268 net.cpp:367] relu6_tnet1 -> scale6_tnet1 (in-place)
I0601 08:31:50.824136  5268 net.cpp:122] Setting up relu6_tnet1
I0601 08:31:50.824151  5268 net.cpp:129] Top shape: 32 512 (16384)
I0601 08:31:50.824158  5268 net.cpp:137] Memory required for data: 1278607744
I0601 08:31:50.824162  5268 layer_factory.hpp:77] Creating layer fc2_tnet1
I0601 08:31:50.824173  5268 net.cpp:84] Creating Layer fc2_tnet1
I0601 08:31:50.824179  5268 net.cpp:406] fc2_tnet1 <- scale6_tnet1
I0601 08:31:50.824188  5268 net.cpp:380] fc2_tnet1 -> fc2_tnet1
I0601 08:31:50.827458  5268 net.cpp:122] Setting up fc2_tnet1
I0601 08:31:50.827472  5268 net.cpp:129] Top shape: 32 256 (8192)
I0601 08:31:50.827476  5268 net.cpp:137] Memory required for data: 1278640512
I0601 08:31:50.827481  5268 layer_factory.hpp:77] Creating layer bn7_tnet1
I0601 08:31:50.827487  5268 net.cpp:84] Creating Layer bn7_tnet1
I0601 08:31:50.827491  5268 net.cpp:406] bn7_tnet1 <- fc2_tnet1
I0601 08:31:50.827502  5268 net.cpp:380] bn7_tnet1 -> bn7_tnet1
I0601 08:31:50.827716  5268 net.cpp:122] Setting up bn7_tnet1
I0601 08:31:50.827728  5268 net.cpp:129] Top shape: 32 256 (8192)
I0601 08:31:50.827733  5268 net.cpp:137] Memory required for data: 1278673280
I0601 08:31:50.827752  5268 layer_factory.hpp:77] Creating layer scale7_tnet1
I0601 08:31:50.827761  5268 net.cpp:84] Creating Layer scale7_tnet1
I0601 08:31:50.827767  5268 net.cpp:406] scale7_tnet1 <- bn7_tnet1
I0601 08:31:50.827776  5268 net.cpp:380] scale7_tnet1 -> scale7_tnet1
I0601 08:31:50.827822  5268 layer_factory.hpp:77] Creating layer scale7_tnet1
I0601 08:31:50.827947  5268 net.cpp:122] Setting up scale7_tnet1
I0601 08:31:50.827957  5268 net.cpp:129] Top shape: 32 256 (8192)
I0601 08:31:50.827963  5268 net.cpp:137] Memory required for data: 1278706048
I0601 08:31:50.827973  5268 layer_factory.hpp:77] Creating layer relu7_tnet1
I0601 08:31:50.827981  5268 net.cpp:84] Creating Layer relu7_tnet1
I0601 08:31:50.827987  5268 net.cpp:406] relu7_tnet1 <- scale7_tnet1
I0601 08:31:50.827996  5268 net.cpp:367] relu7_tnet1 -> scale7_tnet1 (in-place)
I0601 08:31:50.828461  5268 net.cpp:122] Setting up relu7_tnet1
I0601 08:31:50.828476  5268 net.cpp:129] Top shape: 32 256 (8192)
I0601 08:31:50.828483  5268 net.cpp:137] Memory required for data: 1278738816
I0601 08:31:50.828490  5268 layer_factory.hpp:77] Creating layer fc3_tnet1
I0601 08:31:50.828500  5268 net.cpp:84] Creating Layer fc3_tnet1
I0601 08:31:50.828506  5268 net.cpp:406] fc3_tnet1 <- scale7_tnet1
I0601 08:31:50.828516  5268 net.cpp:380] fc3_tnet1 -> fc3_tnet1
I0601 08:31:50.828635  5268 net.cpp:122] Setting up fc3_tnet1
I0601 08:31:50.828662  5268 net.cpp:129] Top shape: 32 9 (288)
I0601 08:31:50.828670  5268 net.cpp:137] Memory required for data: 1278739968
I0601 08:31:50.828680  5268 layer_factory.hpp:77] Creating layer fc3_tnet1_fc3_tnet1_0_split
I0601 08:31:50.828688  5268 net.cpp:84] Creating Layer fc3_tnet1_fc3_tnet1_0_split
I0601 08:31:50.828693  5268 net.cpp:406] fc3_tnet1_fc3_tnet1_0_split <- fc3_tnet1
I0601 08:31:50.828701  5268 net.cpp:380] fc3_tnet1_fc3_tnet1_0_split -> fc3_tnet1_fc3_tnet1_0_split_0
I0601 08:31:50.828709  5268 net.cpp:380] fc3_tnet1_fc3_tnet1_0_split -> fc3_tnet1_fc3_tnet1_0_split_1
I0601 08:31:50.828753  5268 net.cpp:122] Setting up fc3_tnet1_fc3_tnet1_0_split
I0601 08:31:50.828763  5268 net.cpp:129] Top shape: 32 9 (288)
I0601 08:31:50.828768  5268 net.cpp:129] Top shape: 32 9 (288)
I0601 08:31:50.828773  5268 net.cpp:137] Memory required for data: 1278742272
I0601 08:31:50.828778  5268 layer_factory.hpp:77] Creating layer reshape_tnet1
I0601 08:31:50.828786  5268 net.cpp:84] Creating Layer reshape_tnet1
I0601 08:31:50.828793  5268 net.cpp:406] reshape_tnet1 <- fc3_tnet1_fc3_tnet1_0_split_0
I0601 08:31:50.828802  5268 net.cpp:380] reshape_tnet1 -> fc3_tnet1_reshape
I0601 08:31:50.828833  5268 net.cpp:122] Setting up reshape_tnet1
I0601 08:31:50.828843  5268 net.cpp:129] Top shape: 32 3 3 (288)
I0601 08:31:50.828850  5268 net.cpp:137] Memory required for data: 1278743424
I0601 08:31:50.828881  5268 layer_factory.hpp:77] Creating layer eye_tnet1
I0601 08:31:51.378386  5268 net.cpp:84] Creating Layer eye_tnet1
I0601 08:31:51.378432  5268 net.cpp:406] eye_tnet1 <- fc3_tnet1_fc3_tnet1_0_split_1
I0601 08:31:51.378448  5268 net.cpp:380] eye_tnet1 -> eye_tnet1
I0601 08:31:51.378751  5268 net.cpp:122] Setting up eye_tnet1
I0601 08:31:51.378769  5268 net.cpp:129] Top shape: 32 3 3 (288)
I0601 08:31:51.378773  5268 net.cpp:137] Memory required for data: 1278744576
I0601 08:31:51.378780  5268 layer_factory.hpp:77] Creating layer eltwise_sum_tnet1
I0601 08:31:51.378789  5268 net.cpp:84] Creating Layer eltwise_sum_tnet1
I0601 08:31:51.378793  5268 net.cpp:406] eltwise_sum_tnet1 <- fc3_tnet1_reshape
I0601 08:31:51.378798  5268 net.cpp:406] eltwise_sum_tnet1 <- eye_tnet1
I0601 08:31:51.378805  5268 net.cpp:380] eltwise_sum_tnet1 -> transform1
I0601 08:31:51.378839  5268 net.cpp:122] Setting up eltwise_sum_tnet1
I0601 08:31:51.378844  5268 net.cpp:129] Top shape: 32 3 3 (288)
I0601 08:31:51.378847  5268 net.cpp:137] Memory required for data: 1278745728
I0601 08:31:51.378850  5268 layer_factory.hpp:77] Creating layer matmul_input
I0601 08:31:51.378857  5268 net.cpp:84] Creating Layer matmul_input
I0601 08:31:51.378861  5268 net.cpp:406] matmul_input <- data_data_0_split_1
I0601 08:31:51.378865  5268 net.cpp:406] matmul_input <- transform1
I0601 08:31:51.378871  5268 net.cpp:380] matmul_input -> data_transform1
I0601 08:31:51.378906  5268 net.cpp:122] Setting up matmul_input
I0601 08:31:51.378916  5268 net.cpp:129] Top shape: 32 2048 3 (196608)
I0601 08:31:51.378921  5268 net.cpp:137] Memory required for data: 1279532160
I0601 08:31:51.378927  5268 layer_factory.hpp:77] Creating layer reshape
I0601 08:31:51.378937  5268 net.cpp:84] Creating Layer reshape
I0601 08:31:51.378940  5268 net.cpp:406] reshape <- data_transform1
I0601 08:31:51.378945  5268 net.cpp:380] reshape -> data_transform1_reshape
I0601 08:31:51.378978  5268 net.cpp:122] Setting up reshape
I0601 08:31:51.378984  5268 net.cpp:129] Top shape: 32 1 2048 3 (196608)
I0601 08:31:51.378988  5268 net.cpp:137] Memory required for data: 1280318592
I0601 08:31:51.378990  5268 layer_factory.hpp:77] Creating layer conv1
I0601 08:31:51.379020  5268 net.cpp:84] Creating Layer conv1
I0601 08:31:51.379025  5268 net.cpp:406] conv1 <- data_transform1_reshape
I0601 08:31:51.379032  5268 net.cpp:380] conv1 -> conv1
I0601 08:31:51.380486  5268 net.cpp:122] Setting up conv1
I0601 08:31:51.380527  5268 net.cpp:129] Top shape: 32 64 2048 1 (4194304)
I0601 08:31:51.380532  5268 net.cpp:137] Memory required for data: 1297095808
I0601 08:31:51.380548  5268 layer_factory.hpp:77] Creating layer bn1
I0601 08:31:51.380628  5268 net.cpp:84] Creating Layer bn1
I0601 08:31:51.380637  5268 net.cpp:406] bn1 <- conv1
I0601 08:31:51.380648  5268 net.cpp:380] bn1 -> bn1
I0601 08:31:51.380867  5268 net.cpp:122] Setting up bn1
I0601 08:31:51.380880  5268 net.cpp:129] Top shape: 32 64 2048 1 (4194304)
I0601 08:31:51.380884  5268 net.cpp:137] Memory required for data: 1313873024
I0601 08:31:51.380893  5268 layer_factory.hpp:77] Creating layer scale1
I0601 08:31:51.380901  5268 net.cpp:84] Creating Layer scale1
I0601 08:31:51.380905  5268 net.cpp:406] scale1 <- bn1
I0601 08:31:51.380910  5268 net.cpp:380] scale1 -> scale1
I0601 08:31:51.380957  5268 layer_factory.hpp:77] Creating layer scale1
I0601 08:31:51.381047  5268 net.cpp:122] Setting up scale1
I0601 08:31:51.381055  5268 net.cpp:129] Top shape: 32 64 2048 1 (4194304)
I0601 08:31:51.381060  5268 net.cpp:137] Memory required for data: 1330650240
I0601 08:31:51.381068  5268 layer_factory.hpp:77] Creating layer relu1
I0601 08:31:51.381078  5268 net.cpp:84] Creating Layer relu1
I0601 08:31:51.381084  5268 net.cpp:406] relu1 <- scale1
I0601 08:31:51.381093  5268 net.cpp:367] relu1 -> scale1 (in-place)
I0601 08:31:51.381498  5268 net.cpp:122] Setting up relu1
I0601 08:31:51.381511  5268 net.cpp:129] Top shape: 32 64 2048 1 (4194304)
I0601 08:31:51.381516  5268 net.cpp:137] Memory required for data: 1347427456
I0601 08:31:51.381521  5268 layer_factory.hpp:77] Creating layer conv2
I0601 08:31:51.381538  5268 net.cpp:84] Creating Layer conv2
I0601 08:31:51.381544  5268 net.cpp:406] conv2 <- scale1
I0601 08:31:51.381557  5268 net.cpp:380] conv2 -> conv2
I0601 08:31:51.382815  5268 net.cpp:122] Setting up conv2
I0601 08:31:51.382830  5268 net.cpp:129] Top shape: 32 64 2048 1 (4194304)
I0601 08:31:51.382836  5268 net.cpp:137] Memory required for data: 1364204672
I0601 08:31:51.382848  5268 layer_factory.hpp:77] Creating layer bn2
I0601 08:31:51.382858  5268 net.cpp:84] Creating Layer bn2
I0601 08:31:51.382864  5268 net.cpp:406] bn2 <- conv2
I0601 08:31:51.382875  5268 net.cpp:380] bn2 -> bn2
I0601 08:31:51.383046  5268 net.cpp:122] Setting up bn2
I0601 08:31:51.383056  5268 net.cpp:129] Top shape: 32 64 2048 1 (4194304)
I0601 08:31:51.383064  5268 net.cpp:137] Memory required for data: 1380981888
I0601 08:31:51.383075  5268 layer_factory.hpp:77] Creating layer scale2
I0601 08:31:51.383085  5268 net.cpp:84] Creating Layer scale2
I0601 08:31:51.383090  5268 net.cpp:406] scale2 <- bn2
I0601 08:31:51.383100  5268 net.cpp:380] scale2 -> scale2
I0601 08:31:51.383141  5268 layer_factory.hpp:77] Creating layer scale2
I0601 08:31:51.383231  5268 net.cpp:122] Setting up scale2
I0601 08:31:51.383240  5268 net.cpp:129] Top shape: 32 64 2048 1 (4194304)
I0601 08:31:51.383246  5268 net.cpp:137] Memory required for data: 1397759104
I0601 08:31:51.383257  5268 layer_factory.hpp:77] Creating layer relu2
I0601 08:31:51.383265  5268 net.cpp:84] Creating Layer relu2
I0601 08:31:51.383270  5268 net.cpp:406] relu2 <- scale2
I0601 08:31:51.383278  5268 net.cpp:367] relu2 -> scale2 (in-place)
I0601 08:31:51.383445  5268 net.cpp:122] Setting up relu2
I0601 08:31:51.383455  5268 net.cpp:129] Top shape: 32 64 2048 1 (4194304)
I0601 08:31:51.383460  5268 net.cpp:137] Memory required for data: 1414536320
I0601 08:31:51.383466  5268 layer_factory.hpp:77] Creating layer conv3
I0601 08:31:51.383479  5268 net.cpp:84] Creating Layer conv3
I0601 08:31:51.383486  5268 net.cpp:406] conv3 <- scale2
I0601 08:31:51.383496  5268 net.cpp:380] conv3 -> conv3
I0601 08:31:51.384447  5268 net.cpp:122] Setting up conv3
I0601 08:31:51.384460  5268 net.cpp:129] Top shape: 32 64 2048 1 (4194304)
I0601 08:31:51.384466  5268 net.cpp:137] Memory required for data: 1431313536
I0601 08:31:51.384475  5268 layer_factory.hpp:77] Creating layer bn3
I0601 08:31:51.384486  5268 net.cpp:84] Creating Layer bn3
I0601 08:31:51.384492  5268 net.cpp:406] bn3 <- conv3
I0601 08:31:51.384503  5268 net.cpp:380] bn3 -> bn3
I0601 08:31:51.384665  5268 net.cpp:122] Setting up bn3
I0601 08:31:51.384675  5268 net.cpp:129] Top shape: 32 64 2048 1 (4194304)
I0601 08:31:51.384692  5268 net.cpp:137] Memory required for data: 1448090752
I0601 08:31:51.384706  5268 layer_factory.hpp:77] Creating layer scale3
I0601 08:31:51.384714  5268 net.cpp:84] Creating Layer scale3
I0601 08:31:51.384721  5268 net.cpp:406] scale3 <- bn3
I0601 08:31:51.384729  5268 net.cpp:380] scale3 -> scale3
I0601 08:31:51.384769  5268 layer_factory.hpp:77] Creating layer scale3
I0601 08:31:51.384902  5268 net.cpp:122] Setting up scale3
I0601 08:31:51.384914  5268 net.cpp:129] Top shape: 32 64 2048 1 (4194304)
I0601 08:31:51.384919  5268 net.cpp:137] Memory required for data: 1464867968
I0601 08:31:51.384932  5268 layer_factory.hpp:77] Creating layer relu3
I0601 08:31:51.384939  5268 net.cpp:84] Creating Layer relu3
I0601 08:31:51.384945  5268 net.cpp:406] relu3 <- scale3
I0601 08:31:51.384953  5268 net.cpp:367] relu3 -> scale3 (in-place)
I0601 08:31:51.385269  5268 net.cpp:122] Setting up relu3
I0601 08:31:51.385282  5268 net.cpp:129] Top shape: 32 64 2048 1 (4194304)
I0601 08:31:51.385288  5268 net.cpp:137] Memory required for data: 1481645184
I0601 08:31:51.385293  5268 layer_factory.hpp:77] Creating layer conv4
I0601 08:31:51.385305  5268 net.cpp:84] Creating Layer conv4
I0601 08:31:51.385311  5268 net.cpp:406] conv4 <- scale3
I0601 08:31:51.385321  5268 net.cpp:380] conv4 -> conv4
I0601 08:31:51.386292  5268 net.cpp:122] Setting up conv4
I0601 08:31:51.386306  5268 net.cpp:129] Top shape: 32 128 2048 1 (8388608)
I0601 08:31:51.386312  5268 net.cpp:137] Memory required for data: 1515199616
I0601 08:31:51.386320  5268 layer_factory.hpp:77] Creating layer bn4
I0601 08:31:51.386332  5268 net.cpp:84] Creating Layer bn4
I0601 08:31:51.386337  5268 net.cpp:406] bn4 <- conv4
I0601 08:31:51.386346  5268 net.cpp:380] bn4 -> bn4
I0601 08:31:51.386526  5268 net.cpp:122] Setting up bn4
I0601 08:31:51.386538  5268 net.cpp:129] Top shape: 32 128 2048 1 (8388608)
I0601 08:31:51.386543  5268 net.cpp:137] Memory required for data: 1548754048
I0601 08:31:51.386554  5268 layer_factory.hpp:77] Creating layer scale4
I0601 08:31:51.386561  5268 net.cpp:84] Creating Layer scale4
I0601 08:31:51.386567  5268 net.cpp:406] scale4 <- bn4
I0601 08:31:51.386579  5268 net.cpp:380] scale4 -> scale4
I0601 08:31:51.386616  5268 layer_factory.hpp:77] Creating layer scale4
I0601 08:31:51.386704  5268 net.cpp:122] Setting up scale4
I0601 08:31:51.386713  5268 net.cpp:129] Top shape: 32 128 2048 1 (8388608)
I0601 08:31:51.386719  5268 net.cpp:137] Memory required for data: 1582308480
I0601 08:31:51.386749  5268 layer_factory.hpp:77] Creating layer relu4
I0601 08:31:51.386759  5268 net.cpp:84] Creating Layer relu4
I0601 08:31:51.386765  5268 net.cpp:406] relu4 <- scale4
I0601 08:31:51.386772  5268 net.cpp:367] relu4 -> scale4 (in-place)
I0601 08:31:51.386941  5268 net.cpp:122] Setting up relu4
I0601 08:31:51.386952  5268 net.cpp:129] Top shape: 32 128 2048 1 (8388608)
I0601 08:31:51.386957  5268 net.cpp:137] Memory required for data: 1615862912
I0601 08:31:51.386962  5268 layer_factory.hpp:77] Creating layer conv5
I0601 08:31:51.386976  5268 net.cpp:84] Creating Layer conv5
I0601 08:31:51.386981  5268 net.cpp:406] conv5 <- scale4
I0601 08:31:51.386992  5268 net.cpp:380] conv5 -> conv5
I0601 08:31:51.389163  5268 net.cpp:122] Setting up conv5
I0601 08:31:51.389179  5268 net.cpp:129] Top shape: 32 1024 2048 1 (67108864)
I0601 08:31:51.389185  5268 net.cpp:137] Memory required for data: 1884298368
I0601 08:31:51.389196  5268 layer_factory.hpp:77] Creating layer bn5
I0601 08:31:51.389205  5268 net.cpp:84] Creating Layer bn5
I0601 08:31:51.389212  5268 net.cpp:406] bn5 <- conv5
I0601 08:31:51.389223  5268 net.cpp:380] bn5 -> bn5
I0601 08:31:51.389392  5268 net.cpp:122] Setting up bn5
I0601 08:31:51.389402  5268 net.cpp:129] Top shape: 32 1024 2048 1 (67108864)
I0601 08:31:51.389407  5268 net.cpp:137] Memory required for data: 2152733824
I0601 08:31:51.389420  5268 layer_factory.hpp:77] Creating layer scale5
I0601 08:31:51.389430  5268 net.cpp:84] Creating Layer scale5
I0601 08:31:51.389434  5268 net.cpp:406] scale5 <- bn5
I0601 08:31:51.389456  5268 net.cpp:380] scale5 -> scale5
I0601 08:31:51.389494  5268 layer_factory.hpp:77] Creating layer scale5
I0601 08:31:51.389588  5268 net.cpp:122] Setting up scale5
I0601 08:31:51.389598  5268 net.cpp:129] Top shape: 32 1024 2048 1 (67108864)
I0601 08:31:51.389605  5268 net.cpp:137] Memory required for data: 2421169280
I0601 08:31:51.389616  5268 layer_factory.hpp:77] Creating layer relu5
I0601 08:31:51.389622  5268 net.cpp:84] Creating Layer relu5
I0601 08:31:51.389628  5268 net.cpp:406] relu5 <- scale5
I0601 08:31:51.389638  5268 net.cpp:367] relu5 -> scale5 (in-place)
I0601 08:31:51.389981  5268 net.cpp:122] Setting up relu5
I0601 08:31:51.389993  5268 net.cpp:129] Top shape: 32 1024 2048 1 (67108864)
I0601 08:31:51.389999  5268 net.cpp:137] Memory required for data: 2689604736
I0601 08:31:51.390004  5268 layer_factory.hpp:77] Creating layer pool
I0601 08:31:51.390014  5268 net.cpp:84] Creating Layer pool
I0601 08:31:51.390020  5268 net.cpp:406] pool <- scale5
I0601 08:31:51.390030  5268 net.cpp:380] pool -> global_feat
I0601 08:31:51.390074  5268 net.cpp:122] Setting up pool
I0601 08:31:51.390082  5268 net.cpp:129] Top shape: 32 1024 1 1 (32768)
I0601 08:31:51.390089  5268 net.cpp:137] Memory required for data: 2689735808
I0601 08:31:51.390096  5268 layer_factory.hpp:77] Creating layer fc1
I0601 08:31:51.390108  5268 net.cpp:84] Creating Layer fc1
I0601 08:31:51.390113  5268 net.cpp:406] fc1 <- global_feat
I0601 08:31:51.390125  5268 net.cpp:380] fc1 -> fc1
I0601 08:31:51.402462  5268 net.cpp:122] Setting up fc1
I0601 08:31:51.402488  5268 net.cpp:129] Top shape: 32 512 (16384)
I0601 08:31:51.402493  5268 net.cpp:137] Memory required for data: 2689801344
I0601 08:31:51.402505  5268 layer_factory.hpp:77] Creating layer bn6
I0601 08:31:51.402518  5268 net.cpp:84] Creating Layer bn6
I0601 08:31:51.402526  5268 net.cpp:406] bn6 <- fc1
I0601 08:31:51.402536  5268 net.cpp:380] bn6 -> bn6
I0601 08:31:51.402705  5268 net.cpp:122] Setting up bn6
I0601 08:31:51.402715  5268 net.cpp:129] Top shape: 32 512 (16384)
I0601 08:31:51.402720  5268 net.cpp:137] Memory required for data: 2689866880
I0601 08:31:51.402735  5268 layer_factory.hpp:77] Creating layer scale6
I0601 08:31:51.402745  5268 net.cpp:84] Creating Layer scale6
I0601 08:31:51.402751  5268 net.cpp:406] scale6 <- bn6
I0601 08:31:51.402761  5268 net.cpp:380] scale6 -> scale6
I0601 08:31:51.402801  5268 layer_factory.hpp:77] Creating layer scale6
I0601 08:31:51.402896  5268 net.cpp:122] Setting up scale6
I0601 08:31:51.402904  5268 net.cpp:129] Top shape: 32 512 (16384)
I0601 08:31:51.402911  5268 net.cpp:137] Memory required for data: 2689932416
I0601 08:31:51.402921  5268 layer_factory.hpp:77] Creating layer relu6
I0601 08:31:51.402930  5268 net.cpp:84] Creating Layer relu6
I0601 08:31:51.402935  5268 net.cpp:406] relu6 <- scale6
I0601 08:31:51.402945  5268 net.cpp:367] relu6 -> scale6 (in-place)
I0601 08:31:51.403412  5268 net.cpp:122] Setting up relu6
I0601 08:31:51.403425  5268 net.cpp:129] Top shape: 32 512 (16384)
I0601 08:31:51.403431  5268 net.cpp:137] Memory required for data: 2689997952
I0601 08:31:51.403436  5268 layer_factory.hpp:77] Creating layer fc2
I0601 08:31:51.403450  5268 net.cpp:84] Creating Layer fc2
I0601 08:31:51.403455  5268 net.cpp:406] fc2 <- scale6
I0601 08:31:51.403463  5268 net.cpp:380] fc2 -> fc2
I0601 08:31:51.406383  5268 net.cpp:122] Setting up fc2
I0601 08:31:51.406399  5268 net.cpp:129] Top shape: 32 256 (8192)
I0601 08:31:51.406404  5268 net.cpp:137] Memory required for data: 2690030720
I0601 08:31:51.406414  5268 layer_factory.hpp:77] Creating layer bn7
I0601 08:31:51.406425  5268 net.cpp:84] Creating Layer bn7
I0601 08:31:51.406431  5268 net.cpp:406] bn7 <- fc2
I0601 08:31:51.406443  5268 net.cpp:380] bn7 -> bn7
I0601 08:31:51.406633  5268 net.cpp:122] Setting up bn7
I0601 08:31:51.406644  5268 net.cpp:129] Top shape: 32 256 (8192)
I0601 08:31:51.406649  5268 net.cpp:137] Memory required for data: 2690063488
I0601 08:31:51.406661  5268 layer_factory.hpp:77] Creating layer scale7
I0601 08:31:51.406672  5268 net.cpp:84] Creating Layer scale7
I0601 08:31:51.406693  5268 net.cpp:406] scale7 <- bn7
I0601 08:31:51.406704  5268 net.cpp:380] scale7 -> scale7
I0601 08:31:51.406749  5268 layer_factory.hpp:77] Creating layer scale7
I0601 08:31:51.406844  5268 net.cpp:122] Setting up scale7
I0601 08:31:51.406853  5268 net.cpp:129] Top shape: 32 256 (8192)
I0601 08:31:51.406872  5268 net.cpp:137] Memory required for data: 2690096256
I0601 08:31:51.406883  5268 layer_factory.hpp:77] Creating layer relu7
I0601 08:31:51.406893  5268 net.cpp:84] Creating Layer relu7
I0601 08:31:51.406898  5268 net.cpp:406] relu7 <- scale7
I0601 08:31:51.406909  5268 net.cpp:367] relu7 -> scale7 (in-place)
I0601 08:31:51.407145  5268 net.cpp:122] Setting up relu7
I0601 08:31:51.407157  5268 net.cpp:129] Top shape: 32 256 (8192)
I0601 08:31:51.407163  5268 net.cpp:137] Memory required for data: 2690129024
I0601 08:31:51.407168  5268 layer_factory.hpp:77] Creating layer drop1
I0601 08:31:51.407199  5268 net.cpp:84] Creating Layer drop1
I0601 08:31:51.407207  5268 net.cpp:406] drop1 <- scale7
I0601 08:31:51.407217  5268 net.cpp:380] drop1 -> drop1
I0601 08:31:51.407269  5268 net.cpp:122] Setting up drop1
I0601 08:31:51.407279  5268 net.cpp:129] Top shape: 32 256 (8192)
I0601 08:31:51.407284  5268 net.cpp:137] Memory required for data: 2690161792
I0601 08:31:51.407290  5268 layer_factory.hpp:77] Creating layer fc3
I0601 08:31:51.407305  5268 net.cpp:84] Creating Layer fc3
I0601 08:31:51.407310  5268 net.cpp:406] fc3 <- drop1
I0601 08:31:51.407321  5268 net.cpp:380] fc3 -> fc3
I0601 08:31:51.407661  5268 net.cpp:122] Setting up fc3
I0601 08:31:51.407671  5268 net.cpp:129] Top shape: 32 40 (1280)
I0601 08:31:51.407676  5268 net.cpp:137] Memory required for data: 2690166912
I0601 08:31:51.407685  5268 layer_factory.hpp:77] Creating layer fc3_fc3_0_split
I0601 08:31:51.407694  5268 net.cpp:84] Creating Layer fc3_fc3_0_split
I0601 08:31:51.407701  5268 net.cpp:406] fc3_fc3_0_split <- fc3
I0601 08:31:51.407707  5268 net.cpp:380] fc3_fc3_0_split -> fc3_fc3_0_split_0
I0601 08:31:51.407718  5268 net.cpp:380] fc3_fc3_0_split -> fc3_fc3_0_split_1
I0601 08:31:51.407754  5268 net.cpp:122] Setting up fc3_fc3_0_split
I0601 08:31:51.407763  5268 net.cpp:129] Top shape: 32 40 (1280)
I0601 08:31:51.407768  5268 net.cpp:129] Top shape: 32 40 (1280)
I0601 08:31:51.407774  5268 net.cpp:137] Memory required for data: 2690177152
I0601 08:31:51.407780  5268 layer_factory.hpp:77] Creating layer accuracy
I0601 08:31:51.407801  5268 net.cpp:84] Creating Layer accuracy
I0601 08:31:51.407807  5268 net.cpp:406] accuracy <- fc3_fc3_0_split_0
I0601 08:31:51.407814  5268 net.cpp:406] accuracy <- label_data_1_split_0
I0601 08:31:51.407824  5268 net.cpp:380] accuracy -> accuracy
I0601 08:31:51.407835  5268 net.cpp:122] Setting up accuracy
I0601 08:31:51.407840  5268 net.cpp:129] Top shape: (1)
I0601 08:31:51.407846  5268 net.cpp:137] Memory required for data: 2690177156
I0601 08:31:51.407853  5268 layer_factory.hpp:77] Creating layer loss
I0601 08:31:51.407862  5268 net.cpp:84] Creating Layer loss
I0601 08:31:51.407868  5268 net.cpp:406] loss <- fc3_fc3_0_split_1
I0601 08:31:51.407876  5268 net.cpp:406] loss <- label_data_1_split_1
I0601 08:31:51.407887  5268 net.cpp:380] loss -> loss
I0601 08:31:51.407901  5268 layer_factory.hpp:77] Creating layer loss
I0601 08:31:51.408677  5268 net.cpp:122] Setting up loss
I0601 08:31:51.408712  5268 net.cpp:129] Top shape: (1)
I0601 08:31:51.408717  5268 net.cpp:132]     with loss weight 1
I0601 08:31:51.408771  5268 net.cpp:137] Memory required for data: 2690177160
I0601 08:31:51.408778  5268 net.cpp:198] loss needs backward computation.
I0601 08:31:51.408792  5268 net.cpp:200] accuracy does not need backward computation.
I0601 08:31:51.408800  5268 net.cpp:198] fc3_fc3_0_split needs backward computation.
I0601 08:31:51.408807  5268 net.cpp:198] fc3 needs backward computation.
I0601 08:31:51.408821  5268 net.cpp:198] drop1 needs backward computation.
I0601 08:31:51.408828  5268 net.cpp:198] relu7 needs backward computation.
I0601 08:31:51.408833  5268 net.cpp:198] scale7 needs backward computation.
I0601 08:31:51.408910  5268 net.cpp:198] bn7 needs backward computation.
I0601 08:31:51.408920  5268 net.cpp:198] fc2 needs backward computation.
I0601 08:31:51.408927  5268 net.cpp:198] relu6 needs backward computation.
I0601 08:31:51.408934  5268 net.cpp:198] scale6 needs backward computation.
I0601 08:31:51.408949  5268 net.cpp:198] bn6 needs backward computation.
I0601 08:31:51.408955  5268 net.cpp:198] fc1 needs backward computation.
I0601 08:31:51.408960  5268 net.cpp:198] pool needs backward computation.
I0601 08:31:51.408967  5268 net.cpp:198] relu5 needs backward computation.
I0601 08:31:51.408973  5268 net.cpp:198] scale5 needs backward computation.
I0601 08:31:51.408987  5268 net.cpp:198] bn5 needs backward computation.
I0601 08:31:51.409000  5268 net.cpp:198] conv5 needs backward computation.
I0601 08:31:51.409006  5268 net.cpp:198] relu4 needs backward computation.
I0601 08:31:51.409011  5268 net.cpp:198] scale4 needs backward computation.
I0601 08:31:51.409018  5268 net.cpp:198] bn4 needs backward computation.
I0601 08:31:51.409024  5268 net.cpp:198] conv4 needs backward computation.
I0601 08:31:51.409031  5268 net.cpp:198] relu3 needs backward computation.
I0601 08:31:51.409039  5268 net.cpp:198] scale3 needs backward computation.
I0601 08:31:51.409054  5268 net.cpp:198] bn3 needs backward computation.
I0601 08:31:51.409060  5268 net.cpp:198] conv3 needs backward computation.
I0601 08:31:51.409065  5268 net.cpp:198] relu2 needs backward computation.
I0601 08:31:51.409072  5268 net.cpp:198] scale2 needs backward computation.
I0601 08:31:51.409086  5268 net.cpp:198] bn2 needs backward computation.
I0601 08:31:51.409092  5268 net.cpp:198] conv2 needs backward computation.
I0601 08:31:51.409098  5268 net.cpp:198] relu1 needs backward computation.
I0601 08:31:51.409106  5268 net.cpp:198] scale1 needs backward computation.
I0601 08:31:51.409119  5268 net.cpp:198] bn1 needs backward computation.
I0601 08:31:51.409126  5268 net.cpp:198] conv1 needs backward computation.
I0601 08:31:51.409132  5268 net.cpp:198] reshape needs backward computation.
I0601 08:31:51.409140  5268 net.cpp:198] matmul_input needs backward computation.
I0601 08:31:51.409148  5268 net.cpp:198] eltwise_sum_tnet1 needs backward computation.
I0601 08:31:51.409157  5268 net.cpp:198] eye_tnet1 needs backward computation.
I0601 08:31:51.409168  5268 net.cpp:198] reshape_tnet1 needs backward computation.
I0601 08:31:51.409175  5268 net.cpp:198] fc3_tnet1_fc3_tnet1_0_split needs backward computation.
I0601 08:31:51.409183  5268 net.cpp:198] fc3_tnet1 needs backward computation.
I0601 08:31:51.409190  5268 net.cpp:198] relu7_tnet1 needs backward computation.
I0601 08:31:51.409198  5268 net.cpp:198] scale7_tnet1 needs backward computation.
I0601 08:31:51.409205  5268 net.cpp:198] bn7_tnet1 needs backward computation.
I0601 08:31:51.409211  5268 net.cpp:198] fc2_tnet1 needs backward computation.
I0601 08:31:51.409216  5268 net.cpp:198] relu6_tnet1 needs backward computation.
I0601 08:31:51.409222  5268 net.cpp:198] scale6_tnet1 needs backward computation.
I0601 08:31:51.409227  5268 net.cpp:198] bn6_tnet1 needs backward computation.
I0601 08:31:51.409235  5268 net.cpp:198] fc1_tnet1 needs backward computation.
I0601 08:31:51.409241  5268 net.cpp:198] pool_tnet1 needs backward computation.
I0601 08:31:51.409248  5268 net.cpp:198] relu3_tnet1 needs backward computation.
I0601 08:31:51.409255  5268 net.cpp:198] scale3_tnet1 needs backward computation.
I0601 08:31:51.409261  5268 net.cpp:198] bn3_tnet1 needs backward computation.
I0601 08:31:51.409268  5268 net.cpp:198] conv3_tnet1 needs backward computation.
I0601 08:31:51.409276  5268 net.cpp:198] relu2_tnet1 needs backward computation.
I0601 08:31:51.409281  5268 net.cpp:198] scale2_tnet1 needs backward computation.
I0601 08:31:51.409288  5268 net.cpp:198] bn2_tnet1 needs backward computation.
I0601 08:31:51.409294  5268 net.cpp:198] conv2_tnet1 needs backward computation.
I0601 08:31:51.409301  5268 net.cpp:198] relu1_tnet1 needs backward computation.
I0601 08:31:51.409308  5268 net.cpp:198] scale1_tnet1 needs backward computation.
I0601 08:31:51.409323  5268 net.cpp:198] bn1_tnet1 needs backward computation.
I0601 08:31:51.409332  5268 net.cpp:198] conv1_tnet1 needs backward computation.
I0601 08:31:51.409339  5268 net.cpp:200] reshape does not need backward computation.
I0601 08:31:51.409346  5268 net.cpp:200] label_data_1_split does not need backward computation.
I0601 08:31:51.409354  5268 net.cpp:200] data_data_0_split does not need backward computation.
I0601 08:31:51.409363  5268 net.cpp:200] data does not need backward computation.
I0601 08:31:51.409368  5268 net.cpp:242] This network produces output accuracy
I0601 08:31:51.409376  5268 net.cpp:242] This network produces output loss
I0601 08:31:51.409423  5268 net.cpp:255] Network initialization done.
I0601 08:31:51.413717  5268 upgrade_proto.cpp:79] Attempting to upgrade batch norm layers using deprecated params: snapshots/pointnet_cls_input_tnet_iter_80000.caffemodel
I0601 08:31:51.413748  5268 upgrade_proto.cpp:82] Successfully upgraded batch norm layers using deprecated params.
I0601 08:31:51.414911  5268 caffe.cpp:281] Running for 50 iterations.
I0601 08:31:51.629619  5268 caffe.cpp:304] Batch 0, accuracy = 1
I0601 08:31:51.629657  5268 caffe.cpp:304] Batch 0, loss = 0.0372803
I0601 08:31:51.815579  5268 caffe.cpp:304] Batch 1, accuracy = 0.84375
I0601 08:31:51.815630  5268 caffe.cpp:304] Batch 1, loss = 0.703365
I0601 08:31:52.001806  5268 caffe.cpp:304] Batch 2, accuracy = 0.9375
I0601 08:31:52.001837  5268 caffe.cpp:304] Batch 2, loss = 0.277812
I0601 08:31:52.187758  5268 caffe.cpp:304] Batch 3, accuracy = 0.90625
I0601 08:31:52.187791  5268 caffe.cpp:304] Batch 3, loss = 0.448431
I0601 08:31:52.373925  5268 caffe.cpp:304] Batch 4, accuracy = 0.8125
I0601 08:31:52.373956  5268 caffe.cpp:304] Batch 4, loss = 0.668522
I0601 08:31:52.559821  5268 caffe.cpp:304] Batch 5, accuracy = 0.90625
I0601 08:31:52.559875  5268 caffe.cpp:304] Batch 5, loss = 0.148432
I0601 08:31:52.746019  5268 caffe.cpp:304] Batch 6, accuracy = 0.84375
I0601 08:31:52.746050  5268 caffe.cpp:304] Batch 6, loss = 0.760864
I0601 08:31:52.937772  5268 caffe.cpp:304] Batch 7, accuracy = 0.9375
I0601 08:31:52.937800  5268 caffe.cpp:304] Batch 7, loss = 0.150587
I0601 08:31:53.129717  5268 caffe.cpp:304] Batch 8, accuracy = 0.84375
I0601 08:31:53.129761  5268 caffe.cpp:304] Batch 8, loss = 0.885672
I0601 08:31:53.315480  5268 caffe.cpp:304] Batch 9, accuracy = 0.90625
I0601 08:31:53.315515  5268 caffe.cpp:304] Batch 9, loss = 0.463813
I0601 08:31:53.504523  5268 caffe.cpp:304] Batch 10, accuracy = 0.875
I0601 08:31:53.504561  5268 caffe.cpp:304] Batch 10, loss = 0.555181
I0601 08:31:53.690440  5268 caffe.cpp:304] Batch 11, accuracy = 0.9375
I0601 08:31:53.690471  5268 caffe.cpp:304] Batch 11, loss = 0.209889
I0601 08:31:53.879192  5268 caffe.cpp:304] Batch 12, accuracy = 0.84375
I0601 08:31:53.879222  5268 caffe.cpp:304] Batch 12, loss = 0.649835
I0601 08:31:54.071259  5268 caffe.cpp:304] Batch 13, accuracy = 0.90625
I0601 08:31:54.071290  5268 caffe.cpp:304] Batch 13, loss = 0.464727
I0601 08:31:54.259946  5268 caffe.cpp:304] Batch 14, accuracy = 0.90625
I0601 08:31:54.259984  5268 caffe.cpp:304] Batch 14, loss = 0.218482
I0601 08:31:54.448942  5268 caffe.cpp:304] Batch 15, accuracy = 0.875
I0601 08:31:54.448973  5268 caffe.cpp:304] Batch 15, loss = 0.253107
I0601 08:31:54.640969  5268 caffe.cpp:304] Batch 16, accuracy = 0.875
I0601 08:31:54.641001  5268 caffe.cpp:304] Batch 16, loss = 0.396755
I0601 08:31:54.829804  5268 caffe.cpp:304] Batch 17, accuracy = 0.9375
I0601 08:31:54.829833  5268 caffe.cpp:304] Batch 17, loss = 0.392044
I0601 08:31:55.015827  5268 caffe.cpp:304] Batch 18, accuracy = 0.9375
I0601 08:31:55.015873  5268 caffe.cpp:304] Batch 18, loss = 0.32372
I0601 08:31:55.204892  5268 caffe.cpp:304] Batch 19, accuracy = 0.96875
I0601 08:31:55.204937  5268 caffe.cpp:304] Batch 19, loss = 0.284112
I0601 08:31:55.396989  5268 caffe.cpp:304] Batch 20, accuracy = 0.84375
I0601 08:31:55.397018  5268 caffe.cpp:304] Batch 20, loss = 0.670592
I0601 08:31:55.589022  5268 caffe.cpp:304] Batch 21, accuracy = 0.875
I0601 08:31:55.589077  5268 caffe.cpp:304] Batch 21, loss = 0.427656
I0601 08:31:55.781121  5268 caffe.cpp:304] Batch 22, accuracy = 0.96875
I0601 08:31:55.781167  5268 caffe.cpp:304] Batch 22, loss = 0.13772
I0601 08:31:55.972203  5268 caffe.cpp:304] Batch 23, accuracy = 0.78125
I0601 08:31:55.972236  5268 caffe.cpp:304] Batch 23, loss = 1.14594
I0601 08:31:56.155048  5268 caffe.cpp:304] Batch 24, accuracy = 0.84375
I0601 08:31:56.155087  5268 caffe.cpp:304] Batch 24, loss = 0.467483
I0601 08:31:56.341027  5268 caffe.cpp:304] Batch 25, accuracy = 0.875
I0601 08:31:56.341058  5268 caffe.cpp:304] Batch 25, loss = 0.557845
I0601 08:31:56.529909  5268 caffe.cpp:304] Batch 26, accuracy = 0.8125
I0601 08:31:56.529960  5268 caffe.cpp:304] Batch 26, loss = 0.811806
I0601 08:31:56.719094  5268 caffe.cpp:304] Batch 27, accuracy = 0.78125
I0601 08:31:56.719122  5268 caffe.cpp:304] Batch 27, loss = 0.761367
I0601 08:31:56.911342  5268 caffe.cpp:304] Batch 28, accuracy = 0.90625
I0601 08:31:56.911375  5268 caffe.cpp:304] Batch 28, loss = 0.353044
I0601 08:31:57.100270  5268 caffe.cpp:304] Batch 29, accuracy = 0.96875
I0601 08:31:57.100303  5268 caffe.cpp:304] Batch 29, loss = 0.0665813
I0601 08:31:57.292273  5268 caffe.cpp:304] Batch 30, accuracy = 1
I0601 08:31:57.292318  5268 caffe.cpp:304] Batch 30, loss = 0.0233018
I0601 08:31:57.481573  5268 caffe.cpp:304] Batch 31, accuracy = 0.875
I0601 08:31:57.481603  5268 caffe.cpp:304] Batch 31, loss = 0.678642
I0601 08:31:57.670464  5268 caffe.cpp:304] Batch 32, accuracy = 0.875
I0601 08:31:57.670497  5268 caffe.cpp:304] Batch 32, loss = 0.534592
I0601 08:31:57.859478  5268 caffe.cpp:304] Batch 33, accuracy = 0.84375
I0601 08:31:57.859508  5268 caffe.cpp:304] Batch 33, loss = 0.460837
I0601 08:31:58.051558  5268 caffe.cpp:304] Batch 34, accuracy = 0.96875
I0601 08:31:58.051589  5268 caffe.cpp:304] Batch 34, loss = 0.235217
I0601 08:31:58.243517  5268 caffe.cpp:304] Batch 35, accuracy = 0.8125
I0601 08:31:58.243556  5268 caffe.cpp:304] Batch 35, loss = 0.714861
I0601 08:31:58.432484  5268 caffe.cpp:304] Batch 36, accuracy = 0.875
I0601 08:31:58.432515  5268 caffe.cpp:304] Batch 36, loss = 0.500882
I0601 08:31:58.621510  5268 caffe.cpp:304] Batch 37, accuracy = 0.96875
I0601 08:31:58.621542  5268 caffe.cpp:304] Batch 37, loss = 0.197604
I0601 08:31:58.809581  5268 caffe.cpp:304] Batch 38, accuracy = 0.96875
I0601 08:31:58.809608  5268 caffe.cpp:304] Batch 38, loss = 0.329489
I0601 08:31:59.001619  5268 caffe.cpp:304] Batch 39, accuracy = 0.90625
I0601 08:31:59.001652  5268 caffe.cpp:304] Batch 39, loss = 0.223189
I0601 08:31:59.187435  5268 caffe.cpp:304] Batch 40, accuracy = 0.90625
I0601 08:31:59.187467  5268 caffe.cpp:304] Batch 40, loss = 0.312362
I0601 08:31:59.376430  5268 caffe.cpp:304] Batch 41, accuracy = 0.9375
I0601 08:31:59.376485  5268 caffe.cpp:304] Batch 41, loss = 0.182826
I0601 08:31:59.562460  5268 caffe.cpp:304] Batch 42, accuracy = 0.875
I0601 08:31:59.562490  5268 caffe.cpp:304] Batch 42, loss = 0.750993
I0601 08:31:59.751526  5268 caffe.cpp:304] Batch 43, accuracy = 0.875
I0601 08:31:59.751555  5268 caffe.cpp:304] Batch 43, loss = 0.449935
I0601 08:31:59.940462  5268 caffe.cpp:304] Batch 44, accuracy = 0.84375
I0601 08:31:59.940495  5268 caffe.cpp:304] Batch 44, loss = 0.481801
I0601 08:32:00.132380  5268 caffe.cpp:304] Batch 45, accuracy = 0.875
I0601 08:32:00.132412  5268 caffe.cpp:304] Batch 45, loss = 0.700149
I0601 08:32:00.321389  5268 caffe.cpp:304] Batch 46, accuracy = 0.875
I0601 08:32:00.321429  5268 caffe.cpp:304] Batch 46, loss = 0.699922
I0601 08:32:00.507665  5268 caffe.cpp:304] Batch 47, accuracy = 0.90625
I0601 08:32:00.507695  5268 caffe.cpp:304] Batch 47, loss = 0.527802
I0601 08:32:00.693583  5268 caffe.cpp:304] Batch 48, accuracy = 0.875
I0601 08:32:00.693612  5268 caffe.cpp:304] Batch 48, loss = 0.699984
I0601 08:32:00.882452  5268 caffe.cpp:304] Batch 49, accuracy = 0.875
I0601 08:32:00.882479  5268 caffe.cpp:304] Batch 49, loss = 0.449414
I0601 08:32:00.882484  5268 caffe.cpp:309] Loss: 0.456929
I0601 08:32:00.882511  5268 caffe.cpp:321] accuracy = 0.891875
I0601 08:32:00.882519  5268 caffe.cpp:321] loss = 0.456929 (* 1 = 0.456929 loss)
