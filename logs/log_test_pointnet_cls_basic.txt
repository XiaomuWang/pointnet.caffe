I0807 15:36:11.579411 25679 caffe.cpp:266] Use GPU with device ID 0
I0807 15:36:11.618517 25679 caffe.cpp:270] GPU device name: Tesla K40c
I0807 15:36:11.804863 25679 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0807 15:36:11.805052 25679 net.cpp:51] Initializing net from parameters: 
name: "pointnet_cls_basic"
state {
  phase: TEST
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "data/modelnet40_ply_hdf5_2048/test_files.txt"
    batch_size: 32
  }
}
layer {
  name: "reshape"
  type: "Reshape"
  bottom: "data"
  top: "data_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 1
      dim: -1
      dim: 3
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data_reshape"
  top: "conv1"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    kernel_h: 1
    kernel_w: 3
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    kernel_h: 1
    kernel_w: 1
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "conv2"
  top: "conv3"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 64
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    kernel_h: 1
    kernel_w: 1
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "conv3"
  top: "conv3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "conv3"
  top: "conv4"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 128
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    kernel_h: 1
    kernel_w: 1
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "conv4"
  top: "conv4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "conv4"
  top: "conv5"
  param {
    lr_mult: 1
  }
  param {
    lr_mult: 2
  }
  convolution_param {
    num_output: 1024
    pad: 0
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    kernel_h: 1
    kernel_w: 1
  }
}
layer {
  name: "bn5"
  type: "BatchNorm"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "scale5"
  type: "Scale"
  bottom: "conv5"
  top: "conv5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "conv5"
  top: "conv5"
}
layer {
  name: "pool"
  type: "Pooling"
  bottom: "conv5"
  top: "global_feat"
  pooling_param {
    pool: MAX
    stride: 1
    pad: 0
    kernel_h: 2048
    kernel_w: 1
  }
}
layer {
  name: "fc1"
  type: "InnerProduct"
  bottom: "global_feat"
  top: "fc1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  inner_product_param {
    num_output: 512
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn6"
  type: "BatchNorm"
  bottom: "fc1"
  top: "fc1"
}
layer {
  name: "scale6"
  type: "Scale"
  bottom: "fc1"
  top: "fc1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc1"
  top: "fc1"
}
layer {
  name: "fc2"
  type: "InnerProduct"
  bottom: "fc1"
  top: "fc2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  inner_product_param {
    num_output: 256
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn7"
  type: "BatchNorm"
  bottom: "fc2"
  top: "fc2"
}
layer {
  name: "scale7"
  type: "Scale"
  bottom: "fc2"
  top: "fc2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc2"
  top: "fc2"
}
layer {
  name: "drop1"
  type: "Dropout"
  bottom: "fc2"
  top: "drop1"
  dropout_param {
    dropout_ratio: 0.3
  }
}
layer {
  name: "fc3"
  type: "InnerProduct"
  bottom: "drop1"
  top: "fc3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  inner_product_param {
    num_output: 40
    weight_filler {
      type: "gaussian"
      std: 0.001
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc3"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc3"
  bottom: "label"
  top: "loss"
}
I0807 15:36:11.805178 25679 layer_factory.hpp:77] Creating layer data
I0807 15:36:11.805192 25679 net.cpp:84] Creating Layer data
I0807 15:36:11.805197 25679 net.cpp:380] data -> data
I0807 15:36:11.805212 25679 net.cpp:380] data -> label
I0807 15:36:11.805219 25679 hdf5_data_layer.cpp:80] Loading list of HDF5 filenames from: data/modelnet40_ply_hdf5_2048/test_files.txt
I0807 15:36:11.805248 25679 hdf5_data_layer.cpp:94] Number of HDF5 files: 2
I0807 15:36:11.805837 25679 hdf5.cpp:32] Datatype class: H5T_FLOAT
I0807 15:36:12.147804 25679 hdf5.cpp:35] Datatype class: H5T_INTEGER
I0807 15:36:12.148492 25679 net.cpp:122] Setting up data
I0807 15:36:12.148510 25679 net.cpp:129] Top shape: 32 2048 3 (196608)
I0807 15:36:12.148515 25679 net.cpp:129] Top shape: 32 1 (32)
I0807 15:36:12.148519 25679 net.cpp:137] Memory required for data: 786560
I0807 15:36:12.148524 25679 layer_factory.hpp:77] Creating layer label_data_1_split
I0807 15:36:12.148533 25679 net.cpp:84] Creating Layer label_data_1_split
I0807 15:36:12.148540 25679 net.cpp:406] label_data_1_split <- label
I0807 15:36:12.148547 25679 net.cpp:380] label_data_1_split -> label_data_1_split_0
I0807 15:36:12.148556 25679 net.cpp:380] label_data_1_split -> label_data_1_split_1
I0807 15:36:12.148581 25679 net.cpp:122] Setting up label_data_1_split
I0807 15:36:12.148586 25679 net.cpp:129] Top shape: 32 1 (32)
I0807 15:36:12.148589 25679 net.cpp:129] Top shape: 32 1 (32)
I0807 15:36:12.148592 25679 net.cpp:137] Memory required for data: 786816
I0807 15:36:12.148594 25679 layer_factory.hpp:77] Creating layer reshape
I0807 15:36:12.148602 25679 net.cpp:84] Creating Layer reshape
I0807 15:36:12.148605 25679 net.cpp:406] reshape <- data
I0807 15:36:12.148609 25679 net.cpp:380] reshape -> data_reshape
I0807 15:36:12.148629 25679 net.cpp:122] Setting up reshape
I0807 15:36:12.148635 25679 net.cpp:129] Top shape: 32 1 2048 3 (196608)
I0807 15:36:12.148638 25679 net.cpp:137] Memory required for data: 1573248
I0807 15:36:12.148640 25679 layer_factory.hpp:77] Creating layer conv1
I0807 15:36:12.148653 25679 net.cpp:84] Creating Layer conv1
I0807 15:36:12.148656 25679 net.cpp:406] conv1 <- data_reshape
I0807 15:36:12.148660 25679 net.cpp:380] conv1 -> conv1
I0807 15:36:12.397192 25679 net.cpp:122] Setting up conv1
I0807 15:36:12.397236 25679 net.cpp:129] Top shape: 32 64 2048 1 (4194304)
I0807 15:36:12.397241 25679 net.cpp:137] Memory required for data: 18350464
I0807 15:36:12.397258 25679 layer_factory.hpp:77] Creating layer bn1
I0807 15:36:12.397269 25679 net.cpp:84] Creating Layer bn1
I0807 15:36:12.397274 25679 net.cpp:406] bn1 <- conv1
I0807 15:36:12.397281 25679 net.cpp:367] bn1 -> conv1 (in-place)
I0807 15:36:12.397446 25679 net.cpp:122] Setting up bn1
I0807 15:36:12.397455 25679 net.cpp:129] Top shape: 32 64 2048 1 (4194304)
I0807 15:36:12.397457 25679 net.cpp:137] Memory required for data: 35127680
I0807 15:36:12.397466 25679 layer_factory.hpp:77] Creating layer scale1
I0807 15:36:12.397473 25679 net.cpp:84] Creating Layer scale1
I0807 15:36:12.397476 25679 net.cpp:406] scale1 <- conv1
I0807 15:36:12.397480 25679 net.cpp:367] scale1 -> conv1 (in-place)
I0807 15:36:12.397514 25679 layer_factory.hpp:77] Creating layer scale1
I0807 15:36:12.397596 25679 net.cpp:122] Setting up scale1
I0807 15:36:12.397603 25679 net.cpp:129] Top shape: 32 64 2048 1 (4194304)
I0807 15:36:12.397605 25679 net.cpp:137] Memory required for data: 51904896
I0807 15:36:12.397610 25679 layer_factory.hpp:77] Creating layer relu1
I0807 15:36:12.397615 25679 net.cpp:84] Creating Layer relu1
I0807 15:36:12.397619 25679 net.cpp:406] relu1 <- conv1
I0807 15:36:12.397621 25679 net.cpp:367] relu1 -> conv1 (in-place)
I0807 15:36:12.397898 25679 net.cpp:122] Setting up relu1
I0807 15:36:12.397909 25679 net.cpp:129] Top shape: 32 64 2048 1 (4194304)
I0807 15:36:12.397912 25679 net.cpp:137] Memory required for data: 68682112
I0807 15:36:12.397915 25679 layer_factory.hpp:77] Creating layer conv2
I0807 15:36:12.397924 25679 net.cpp:84] Creating Layer conv2
I0807 15:36:12.397928 25679 net.cpp:406] conv2 <- conv1
I0807 15:36:12.397933 25679 net.cpp:380] conv2 -> conv2
I0807 15:36:12.398811 25679 net.cpp:122] Setting up conv2
I0807 15:36:12.398823 25679 net.cpp:129] Top shape: 32 64 2048 1 (4194304)
I0807 15:36:12.398828 25679 net.cpp:137] Memory required for data: 85459328
I0807 15:36:12.398835 25679 layer_factory.hpp:77] Creating layer bn2
I0807 15:36:12.398844 25679 net.cpp:84] Creating Layer bn2
I0807 15:36:12.398847 25679 net.cpp:406] bn2 <- conv2
I0807 15:36:12.398852 25679 net.cpp:367] bn2 -> conv2 (in-place)
I0807 15:36:12.398991 25679 net.cpp:122] Setting up bn2
I0807 15:36:12.398998 25679 net.cpp:129] Top shape: 32 64 2048 1 (4194304)
I0807 15:36:12.399000 25679 net.cpp:137] Memory required for data: 102236544
I0807 15:36:12.399006 25679 layer_factory.hpp:77] Creating layer scale2
I0807 15:36:12.399010 25679 net.cpp:84] Creating Layer scale2
I0807 15:36:12.399013 25679 net.cpp:406] scale2 <- conv2
I0807 15:36:12.399016 25679 net.cpp:367] scale2 -> conv2 (in-place)
I0807 15:36:12.399045 25679 layer_factory.hpp:77] Creating layer scale2
I0807 15:36:12.399125 25679 net.cpp:122] Setting up scale2
I0807 15:36:12.399132 25679 net.cpp:129] Top shape: 32 64 2048 1 (4194304)
I0807 15:36:12.399133 25679 net.cpp:137] Memory required for data: 119013760
I0807 15:36:12.399138 25679 layer_factory.hpp:77] Creating layer relu2
I0807 15:36:12.399143 25679 net.cpp:84] Creating Layer relu2
I0807 15:36:12.399147 25679 net.cpp:406] relu2 <- conv2
I0807 15:36:12.399149 25679 net.cpp:367] relu2 -> conv2 (in-place)
I0807 15:36:12.399294 25679 net.cpp:122] Setting up relu2
I0807 15:36:12.399303 25679 net.cpp:129] Top shape: 32 64 2048 1 (4194304)
I0807 15:36:12.399307 25679 net.cpp:137] Memory required for data: 135790976
I0807 15:36:12.399308 25679 layer_factory.hpp:77] Creating layer conv3
I0807 15:36:12.399317 25679 net.cpp:84] Creating Layer conv3
I0807 15:36:12.399322 25679 net.cpp:406] conv3 <- conv2
I0807 15:36:12.399327 25679 net.cpp:380] conv3 -> conv3
I0807 15:36:12.400225 25679 net.cpp:122] Setting up conv3
I0807 15:36:12.400238 25679 net.cpp:129] Top shape: 32 64 2048 1 (4194304)
I0807 15:36:12.400240 25679 net.cpp:137] Memory required for data: 152568192
I0807 15:36:12.400246 25679 layer_factory.hpp:77] Creating layer bn3
I0807 15:36:12.400251 25679 net.cpp:84] Creating Layer bn3
I0807 15:36:12.400264 25679 net.cpp:406] bn3 <- conv3
I0807 15:36:12.400270 25679 net.cpp:367] bn3 -> conv3 (in-place)
I0807 15:36:12.400411 25679 net.cpp:122] Setting up bn3
I0807 15:36:12.400418 25679 net.cpp:129] Top shape: 32 64 2048 1 (4194304)
I0807 15:36:12.400421 25679 net.cpp:137] Memory required for data: 169345408
I0807 15:36:12.400429 25679 layer_factory.hpp:77] Creating layer scale3
I0807 15:36:12.400435 25679 net.cpp:84] Creating Layer scale3
I0807 15:36:12.400439 25679 net.cpp:406] scale3 <- conv3
I0807 15:36:12.400444 25679 net.cpp:367] scale3 -> conv3 (in-place)
I0807 15:36:12.400472 25679 layer_factory.hpp:77] Creating layer scale3
I0807 15:36:12.400552 25679 net.cpp:122] Setting up scale3
I0807 15:36:12.400558 25679 net.cpp:129] Top shape: 32 64 2048 1 (4194304)
I0807 15:36:12.400562 25679 net.cpp:137] Memory required for data: 186122624
I0807 15:36:12.400566 25679 layer_factory.hpp:77] Creating layer relu3
I0807 15:36:12.400573 25679 net.cpp:84] Creating Layer relu3
I0807 15:36:12.400576 25679 net.cpp:406] relu3 <- conv3
I0807 15:36:12.400579 25679 net.cpp:367] relu3 -> conv3 (in-place)
I0807 15:36:12.400856 25679 net.cpp:122] Setting up relu3
I0807 15:36:12.400866 25679 net.cpp:129] Top shape: 32 64 2048 1 (4194304)
I0807 15:36:12.400871 25679 net.cpp:137] Memory required for data: 202899840
I0807 15:36:12.400873 25679 layer_factory.hpp:77] Creating layer conv4
I0807 15:36:12.400882 25679 net.cpp:84] Creating Layer conv4
I0807 15:36:12.400885 25679 net.cpp:406] conv4 <- conv3
I0807 15:36:12.400890 25679 net.cpp:380] conv4 -> conv4
I0807 15:36:12.402202 25679 net.cpp:122] Setting up conv4
I0807 15:36:12.402215 25679 net.cpp:129] Top shape: 32 128 2048 1 (8388608)
I0807 15:36:12.402220 25679 net.cpp:137] Memory required for data: 236454272
I0807 15:36:12.402225 25679 layer_factory.hpp:77] Creating layer bn4
I0807 15:36:12.402233 25679 net.cpp:84] Creating Layer bn4
I0807 15:36:12.402237 25679 net.cpp:406] bn4 <- conv4
I0807 15:36:12.402241 25679 net.cpp:367] bn4 -> conv4 (in-place)
I0807 15:36:12.402377 25679 net.cpp:122] Setting up bn4
I0807 15:36:12.402384 25679 net.cpp:129] Top shape: 32 128 2048 1 (8388608)
I0807 15:36:12.402386 25679 net.cpp:137] Memory required for data: 270008704
I0807 15:36:12.402392 25679 layer_factory.hpp:77] Creating layer scale4
I0807 15:36:12.402397 25679 net.cpp:84] Creating Layer scale4
I0807 15:36:12.402401 25679 net.cpp:406] scale4 <- conv4
I0807 15:36:12.402405 25679 net.cpp:367] scale4 -> conv4 (in-place)
I0807 15:36:12.402434 25679 layer_factory.hpp:77] Creating layer scale4
I0807 15:36:12.402511 25679 net.cpp:122] Setting up scale4
I0807 15:36:12.402518 25679 net.cpp:129] Top shape: 32 128 2048 1 (8388608)
I0807 15:36:12.402519 25679 net.cpp:137] Memory required for data: 303563136
I0807 15:36:12.402524 25679 layer_factory.hpp:77] Creating layer relu4
I0807 15:36:12.402529 25679 net.cpp:84] Creating Layer relu4
I0807 15:36:12.402531 25679 net.cpp:406] relu4 <- conv4
I0807 15:36:12.402536 25679 net.cpp:367] relu4 -> conv4 (in-place)
I0807 15:36:12.402684 25679 net.cpp:122] Setting up relu4
I0807 15:36:12.402693 25679 net.cpp:129] Top shape: 32 128 2048 1 (8388608)
I0807 15:36:12.402695 25679 net.cpp:137] Memory required for data: 337117568
I0807 15:36:12.402698 25679 layer_factory.hpp:77] Creating layer conv5
I0807 15:36:12.402707 25679 net.cpp:84] Creating Layer conv5
I0807 15:36:12.402711 25679 net.cpp:406] conv5 <- conv4
I0807 15:36:12.402716 25679 net.cpp:380] conv5 -> conv5
I0807 15:36:12.404943 25679 net.cpp:122] Setting up conv5
I0807 15:36:12.404956 25679 net.cpp:129] Top shape: 32 1024 2048 1 (67108864)
I0807 15:36:12.404959 25679 net.cpp:137] Memory required for data: 605553024
I0807 15:36:12.404964 25679 layer_factory.hpp:77] Creating layer bn5
I0807 15:36:12.404970 25679 net.cpp:84] Creating Layer bn5
I0807 15:36:12.404974 25679 net.cpp:406] bn5 <- conv5
I0807 15:36:12.404980 25679 net.cpp:367] bn5 -> conv5 (in-place)
I0807 15:36:12.405122 25679 net.cpp:122] Setting up bn5
I0807 15:36:12.405128 25679 net.cpp:129] Top shape: 32 1024 2048 1 (67108864)
I0807 15:36:12.405140 25679 net.cpp:137] Memory required for data: 873988480
I0807 15:36:12.405151 25679 layer_factory.hpp:77] Creating layer scale5
I0807 15:36:12.405156 25679 net.cpp:84] Creating Layer scale5
I0807 15:36:12.405159 25679 net.cpp:406] scale5 <- conv5
I0807 15:36:12.405164 25679 net.cpp:367] scale5 -> conv5 (in-place)
I0807 15:36:12.405191 25679 layer_factory.hpp:77] Creating layer scale5
I0807 15:36:12.405273 25679 net.cpp:122] Setting up scale5
I0807 15:36:12.405279 25679 net.cpp:129] Top shape: 32 1024 2048 1 (67108864)
I0807 15:36:12.405282 25679 net.cpp:137] Memory required for data: 1142423936
I0807 15:36:12.405287 25679 layer_factory.hpp:77] Creating layer relu5
I0807 15:36:12.405292 25679 net.cpp:84] Creating Layer relu5
I0807 15:36:12.405294 25679 net.cpp:406] relu5 <- conv5
I0807 15:36:12.405298 25679 net.cpp:367] relu5 -> conv5 (in-place)
I0807 15:36:12.405578 25679 net.cpp:122] Setting up relu5
I0807 15:36:12.405588 25679 net.cpp:129] Top shape: 32 1024 2048 1 (67108864)
I0807 15:36:12.405591 25679 net.cpp:137] Memory required for data: 1410859392
I0807 15:36:12.405594 25679 layer_factory.hpp:77] Creating layer pool
I0807 15:36:12.405601 25679 net.cpp:84] Creating Layer pool
I0807 15:36:12.405604 25679 net.cpp:406] pool <- conv5
I0807 15:36:12.405608 25679 net.cpp:380] pool -> global_feat
I0807 15:36:12.405647 25679 net.cpp:122] Setting up pool
I0807 15:36:12.405654 25679 net.cpp:129] Top shape: 32 1024 1 1 (32768)
I0807 15:36:12.405656 25679 net.cpp:137] Memory required for data: 1410990464
I0807 15:36:12.405659 25679 layer_factory.hpp:77] Creating layer fc1
I0807 15:36:12.405665 25679 net.cpp:84] Creating Layer fc1
I0807 15:36:12.405668 25679 net.cpp:406] fc1 <- global_feat
I0807 15:36:12.405673 25679 net.cpp:380] fc1 -> fc1
I0807 15:36:12.417428 25679 net.cpp:122] Setting up fc1
I0807 15:36:12.417449 25679 net.cpp:129] Top shape: 32 512 (16384)
I0807 15:36:12.417452 25679 net.cpp:137] Memory required for data: 1411056000
I0807 15:36:12.417459 25679 layer_factory.hpp:77] Creating layer bn6
I0807 15:36:12.417465 25679 net.cpp:84] Creating Layer bn6
I0807 15:36:12.417469 25679 net.cpp:406] bn6 <- fc1
I0807 15:36:12.417475 25679 net.cpp:367] bn6 -> fc1 (in-place)
I0807 15:36:12.417616 25679 net.cpp:122] Setting up bn6
I0807 15:36:12.417623 25679 net.cpp:129] Top shape: 32 512 (16384)
I0807 15:36:12.417625 25679 net.cpp:137] Memory required for data: 1411121536
I0807 15:36:12.417630 25679 layer_factory.hpp:77] Creating layer scale6
I0807 15:36:12.417635 25679 net.cpp:84] Creating Layer scale6
I0807 15:36:12.417639 25679 net.cpp:406] scale6 <- fc1
I0807 15:36:12.417642 25679 net.cpp:367] scale6 -> fc1 (in-place)
I0807 15:36:12.417670 25679 layer_factory.hpp:77] Creating layer scale6
I0807 15:36:12.417752 25679 net.cpp:122] Setting up scale6
I0807 15:36:12.417757 25679 net.cpp:129] Top shape: 32 512 (16384)
I0807 15:36:12.417759 25679 net.cpp:137] Memory required for data: 1411187072
I0807 15:36:12.417764 25679 layer_factory.hpp:77] Creating layer relu6
I0807 15:36:12.417769 25679 net.cpp:84] Creating Layer relu6
I0807 15:36:12.417773 25679 net.cpp:406] relu6 <- fc1
I0807 15:36:12.417775 25679 net.cpp:367] relu6 -> fc1 (in-place)
I0807 15:36:12.418124 25679 net.cpp:122] Setting up relu6
I0807 15:36:12.418135 25679 net.cpp:129] Top shape: 32 512 (16384)
I0807 15:36:12.418138 25679 net.cpp:137] Memory required for data: 1411252608
I0807 15:36:12.418141 25679 layer_factory.hpp:77] Creating layer fc2
I0807 15:36:12.418148 25679 net.cpp:84] Creating Layer fc2
I0807 15:36:12.418153 25679 net.cpp:406] fc2 <- fc1
I0807 15:36:12.418159 25679 net.cpp:380] fc2 -> fc2
I0807 15:36:12.421012 25679 net.cpp:122] Setting up fc2
I0807 15:36:12.421020 25679 net.cpp:129] Top shape: 32 256 (8192)
I0807 15:36:12.421022 25679 net.cpp:137] Memory required for data: 1411285376
I0807 15:36:12.421027 25679 layer_factory.hpp:77] Creating layer bn7
I0807 15:36:12.421032 25679 net.cpp:84] Creating Layer bn7
I0807 15:36:12.421036 25679 net.cpp:406] bn7 <- fc2
I0807 15:36:12.421041 25679 net.cpp:367] bn7 -> fc2 (in-place)
I0807 15:36:12.421188 25679 net.cpp:122] Setting up bn7
I0807 15:36:12.421195 25679 net.cpp:129] Top shape: 32 256 (8192)
I0807 15:36:12.421197 25679 net.cpp:137] Memory required for data: 1411318144
I0807 15:36:12.421203 25679 layer_factory.hpp:77] Creating layer scale7
I0807 15:36:12.421209 25679 net.cpp:84] Creating Layer scale7
I0807 15:36:12.421212 25679 net.cpp:406] scale7 <- fc2
I0807 15:36:12.421216 25679 net.cpp:367] scale7 -> fc2 (in-place)
I0807 15:36:12.421244 25679 layer_factory.hpp:77] Creating layer scale7
I0807 15:36:12.421321 25679 net.cpp:122] Setting up scale7
I0807 15:36:12.421327 25679 net.cpp:129] Top shape: 32 256 (8192)
I0807 15:36:12.421329 25679 net.cpp:137] Memory required for data: 1411350912
I0807 15:36:12.421334 25679 layer_factory.hpp:77] Creating layer relu7
I0807 15:36:12.421339 25679 net.cpp:84] Creating Layer relu7
I0807 15:36:12.421342 25679 net.cpp:406] relu7 <- fc2
I0807 15:36:12.421345 25679 net.cpp:367] relu7 -> fc2 (in-place)
I0807 15:36:12.421499 25679 net.cpp:122] Setting up relu7
I0807 15:36:12.421505 25679 net.cpp:129] Top shape: 32 256 (8192)
I0807 15:36:12.421509 25679 net.cpp:137] Memory required for data: 1411383680
I0807 15:36:12.421511 25679 layer_factory.hpp:77] Creating layer drop1
I0807 15:36:12.421521 25679 net.cpp:84] Creating Layer drop1
I0807 15:36:12.421525 25679 net.cpp:406] drop1 <- fc2
I0807 15:36:12.421530 25679 net.cpp:380] drop1 -> drop1
I0807 15:36:12.421562 25679 net.cpp:122] Setting up drop1
I0807 15:36:12.421568 25679 net.cpp:129] Top shape: 32 256 (8192)
I0807 15:36:12.421571 25679 net.cpp:137] Memory required for data: 1411416448
I0807 15:36:12.421573 25679 layer_factory.hpp:77] Creating layer fc3
I0807 15:36:12.421579 25679 net.cpp:84] Creating Layer fc3
I0807 15:36:12.421582 25679 net.cpp:406] fc3 <- drop1
I0807 15:36:12.421588 25679 net.cpp:380] fc3 -> fc3
I0807 15:36:12.421885 25679 net.cpp:122] Setting up fc3
I0807 15:36:12.421892 25679 net.cpp:129] Top shape: 32 40 (1280)
I0807 15:36:12.421895 25679 net.cpp:137] Memory required for data: 1411421568
I0807 15:36:12.421900 25679 layer_factory.hpp:77] Creating layer fc3_fc3_0_split
I0807 15:36:12.421905 25679 net.cpp:84] Creating Layer fc3_fc3_0_split
I0807 15:36:12.421907 25679 net.cpp:406] fc3_fc3_0_split <- fc3
I0807 15:36:12.421911 25679 net.cpp:380] fc3_fc3_0_split -> fc3_fc3_0_split_0
I0807 15:36:12.421916 25679 net.cpp:380] fc3_fc3_0_split -> fc3_fc3_0_split_1
I0807 15:36:12.421943 25679 net.cpp:122] Setting up fc3_fc3_0_split
I0807 15:36:12.421949 25679 net.cpp:129] Top shape: 32 40 (1280)
I0807 15:36:12.421952 25679 net.cpp:129] Top shape: 32 40 (1280)
I0807 15:36:12.421955 25679 net.cpp:137] Memory required for data: 1411431808
I0807 15:36:12.421957 25679 layer_factory.hpp:77] Creating layer accuracy
I0807 15:36:12.421962 25679 net.cpp:84] Creating Layer accuracy
I0807 15:36:12.421967 25679 net.cpp:406] accuracy <- fc3_fc3_0_split_0
I0807 15:36:12.421969 25679 net.cpp:406] accuracy <- label_data_1_split_0
I0807 15:36:12.421973 25679 net.cpp:380] accuracy -> accuracy
I0807 15:36:12.421979 25679 net.cpp:122] Setting up accuracy
I0807 15:36:12.421983 25679 net.cpp:129] Top shape: (1)
I0807 15:36:12.421985 25679 net.cpp:137] Memory required for data: 1411431812
I0807 15:36:12.421988 25679 layer_factory.hpp:77] Creating layer loss
I0807 15:36:12.421993 25679 net.cpp:84] Creating Layer loss
I0807 15:36:12.421995 25679 net.cpp:406] loss <- fc3_fc3_0_split_1
I0807 15:36:12.422000 25679 net.cpp:406] loss <- label_data_1_split_1
I0807 15:36:12.422005 25679 net.cpp:380] loss -> loss
I0807 15:36:12.422013 25679 layer_factory.hpp:77] Creating layer loss
I0807 15:36:12.422363 25679 net.cpp:122] Setting up loss
I0807 15:36:12.422374 25679 net.cpp:129] Top shape: (1)
I0807 15:36:12.422377 25679 net.cpp:132]     with loss weight 1
I0807 15:36:12.422390 25679 net.cpp:137] Memory required for data: 1411431816
I0807 15:36:12.422394 25679 net.cpp:198] loss needs backward computation.
I0807 15:36:12.422399 25679 net.cpp:200] accuracy does not need backward computation.
I0807 15:36:12.422401 25679 net.cpp:198] fc3_fc3_0_split needs backward computation.
I0807 15:36:12.422412 25679 net.cpp:198] fc3 needs backward computation.
I0807 15:36:12.422415 25679 net.cpp:198] drop1 needs backward computation.
I0807 15:36:12.422417 25679 net.cpp:198] relu7 needs backward computation.
I0807 15:36:12.422420 25679 net.cpp:198] scale7 needs backward computation.
I0807 15:36:12.422422 25679 net.cpp:198] bn7 needs backward computation.
I0807 15:36:12.422425 25679 net.cpp:198] fc2 needs backward computation.
I0807 15:36:12.422427 25679 net.cpp:198] relu6 needs backward computation.
I0807 15:36:12.422430 25679 net.cpp:198] scale6 needs backward computation.
I0807 15:36:12.422431 25679 net.cpp:198] bn6 needs backward computation.
I0807 15:36:12.422433 25679 net.cpp:198] fc1 needs backward computation.
I0807 15:36:12.422436 25679 net.cpp:198] pool needs backward computation.
I0807 15:36:12.422439 25679 net.cpp:198] relu5 needs backward computation.
I0807 15:36:12.422441 25679 net.cpp:198] scale5 needs backward computation.
I0807 15:36:12.422443 25679 net.cpp:198] bn5 needs backward computation.
I0807 15:36:12.422446 25679 net.cpp:198] conv5 needs backward computation.
I0807 15:36:12.422449 25679 net.cpp:198] relu4 needs backward computation.
I0807 15:36:12.422451 25679 net.cpp:198] scale4 needs backward computation.
I0807 15:36:12.422453 25679 net.cpp:198] bn4 needs backward computation.
I0807 15:36:12.422456 25679 net.cpp:198] conv4 needs backward computation.
I0807 15:36:12.422458 25679 net.cpp:198] relu3 needs backward computation.
I0807 15:36:12.422461 25679 net.cpp:198] scale3 needs backward computation.
I0807 15:36:12.422463 25679 net.cpp:198] bn3 needs backward computation.
I0807 15:36:12.422466 25679 net.cpp:198] conv3 needs backward computation.
I0807 15:36:12.422468 25679 net.cpp:198] relu2 needs backward computation.
I0807 15:36:12.422472 25679 net.cpp:198] scale2 needs backward computation.
I0807 15:36:12.422473 25679 net.cpp:198] bn2 needs backward computation.
I0807 15:36:12.422475 25679 net.cpp:198] conv2 needs backward computation.
I0807 15:36:12.422478 25679 net.cpp:198] relu1 needs backward computation.
I0807 15:36:12.422480 25679 net.cpp:198] scale1 needs backward computation.
I0807 15:36:12.422483 25679 net.cpp:198] bn1 needs backward computation.
I0807 15:36:12.422485 25679 net.cpp:198] conv1 needs backward computation.
I0807 15:36:12.422488 25679 net.cpp:200] reshape does not need backward computation.
I0807 15:36:12.422492 25679 net.cpp:200] label_data_1_split does not need backward computation.
I0807 15:36:12.422495 25679 net.cpp:200] data does not need backward computation.
I0807 15:36:12.422497 25679 net.cpp:242] This network produces output accuracy
I0807 15:36:12.422500 25679 net.cpp:242] This network produces output loss
I0807 15:36:12.422516 25679 net.cpp:255] Network initialization done.
I0807 15:36:12.423961 25679 upgrade_proto.cpp:79] Attempting to upgrade batch norm layers using deprecated params: snapshots/pointnet_cls_basic_iter_80000.caffemodel
I0807 15:36:12.423976 25679 upgrade_proto.cpp:82] Successfully upgraded batch norm layers using deprecated params.
I0807 15:36:12.424450 25679 caffe.cpp:281] Running for 77 iterations.
I0807 15:36:12.531049 25679 caffe.cpp:304] Batch 0, accuracy = 1
I0807 15:36:12.531078 25679 caffe.cpp:304] Batch 0, loss = 0.0134182
I0807 15:36:12.627564 25679 caffe.cpp:304] Batch 1, accuracy = 0.8125
I0807 15:36:12.627588 25679 caffe.cpp:304] Batch 1, loss = 0.916117
I0807 15:36:12.727063 25679 caffe.cpp:304] Batch 2, accuracy = 0.875
I0807 15:36:12.727085 25679 caffe.cpp:304] Batch 2, loss = 0.372647
I0807 15:36:12.823559 25679 caffe.cpp:304] Batch 3, accuracy = 0.90625
I0807 15:36:12.823582 25679 caffe.cpp:304] Batch 3, loss = 0.361361
I0807 15:36:12.922971 25679 caffe.cpp:304] Batch 4, accuracy = 0.875
I0807 15:36:12.922993 25679 caffe.cpp:304] Batch 4, loss = 0.583194
I0807 15:36:13.016342 25679 caffe.cpp:304] Batch 5, accuracy = 0.90625
I0807 15:36:13.016366 25679 caffe.cpp:304] Batch 5, loss = 0.296769
I0807 15:36:13.115888 25679 caffe.cpp:304] Batch 6, accuracy = 0.875
I0807 15:36:13.115909 25679 caffe.cpp:304] Batch 6, loss = 0.784413
I0807 15:36:13.215387 25679 caffe.cpp:304] Batch 7, accuracy = 0.9375
I0807 15:36:13.215409 25679 caffe.cpp:304] Batch 7, loss = 0.162475
I0807 15:36:13.315006 25679 caffe.cpp:304] Batch 8, accuracy = 0.8125
I0807 15:36:13.315029 25679 caffe.cpp:304] Batch 8, loss = 0.860878
I0807 15:36:13.414503 25679 caffe.cpp:304] Batch 9, accuracy = 0.9375
I0807 15:36:13.414526 25679 caffe.cpp:304] Batch 9, loss = 0.373962
I0807 15:36:13.510946 25679 caffe.cpp:304] Batch 10, accuracy = 0.875
I0807 15:36:13.510970 25679 caffe.cpp:304] Batch 10, loss = 0.513647
I0807 15:36:13.610469 25679 caffe.cpp:304] Batch 11, accuracy = 0.9375
I0807 15:36:13.610493 25679 caffe.cpp:304] Batch 11, loss = 0.329943
I0807 15:36:13.706990 25679 caffe.cpp:304] Batch 12, accuracy = 0.84375
I0807 15:36:13.707012 25679 caffe.cpp:304] Batch 12, loss = 0.482391
I0807 15:36:13.803478 25679 caffe.cpp:304] Batch 13, accuracy = 0.875
I0807 15:36:13.803499 25679 caffe.cpp:304] Batch 13, loss = 0.664824
I0807 15:36:13.899904 25679 caffe.cpp:304] Batch 14, accuracy = 0.90625
I0807 15:36:13.899924 25679 caffe.cpp:304] Batch 14, loss = 0.369941
I0807 15:36:13.996456 25679 caffe.cpp:304] Batch 15, accuracy = 0.90625
I0807 15:36:13.996476 25679 caffe.cpp:304] Batch 15, loss = 0.412343
I0807 15:36:14.092847 25679 caffe.cpp:304] Batch 16, accuracy = 0.84375
I0807 15:36:14.092869 25679 caffe.cpp:304] Batch 16, loss = 0.636792
I0807 15:36:14.189278 25679 caffe.cpp:304] Batch 17, accuracy = 0.90625
I0807 15:36:14.189299 25679 caffe.cpp:304] Batch 17, loss = 0.242074
I0807 15:36:14.282737 25679 caffe.cpp:304] Batch 18, accuracy = 0.96875
I0807 15:36:14.282760 25679 caffe.cpp:304] Batch 18, loss = 0.188461
I0807 15:36:14.379251 25679 caffe.cpp:304] Batch 19, accuracy = 0.90625
I0807 15:36:14.379272 25679 caffe.cpp:304] Batch 19, loss = 0.328926
I0807 15:36:14.475653 25679 caffe.cpp:304] Batch 20, accuracy = 0.8125
I0807 15:36:14.475674 25679 caffe.cpp:304] Batch 20, loss = 0.791411
I0807 15:36:14.568966 25679 caffe.cpp:304] Batch 21, accuracy = 0.90625
I0807 15:36:14.568990 25679 caffe.cpp:304] Batch 21, loss = 0.435887
I0807 15:36:14.665258 25679 caffe.cpp:304] Batch 22, accuracy = 0.96875
I0807 15:36:14.665282 25679 caffe.cpp:304] Batch 22, loss = 0.164913
I0807 15:36:14.761736 25679 caffe.cpp:304] Batch 23, accuracy = 0.75
I0807 15:36:14.761757 25679 caffe.cpp:304] Batch 23, loss = 1.11532
I0807 15:36:14.861197 25679 caffe.cpp:304] Batch 24, accuracy = 0.84375
I0807 15:36:14.861219 25679 caffe.cpp:304] Batch 24, loss = 0.462583
I0807 15:36:14.957583 25679 caffe.cpp:304] Batch 25, accuracy = 0.84375
I0807 15:36:14.957604 25679 caffe.cpp:304] Batch 25, loss = 0.527657
I0807 15:36:15.054147 25679 caffe.cpp:304] Batch 26, accuracy = 0.6875
I0807 15:36:15.054170 25679 caffe.cpp:304] Batch 26, loss = 1.27331
I0807 15:36:15.150527 25679 caffe.cpp:304] Batch 27, accuracy = 0.84375
I0807 15:36:15.150547 25679 caffe.cpp:304] Batch 27, loss = 0.828355
I0807 15:36:15.246932 25679 caffe.cpp:304] Batch 28, accuracy = 0.90625
I0807 15:36:15.246953 25679 caffe.cpp:304] Batch 28, loss = 0.250032
I0807 15:36:15.343436 25679 caffe.cpp:304] Batch 29, accuracy = 0.96875
I0807 15:36:15.343458 25679 caffe.cpp:304] Batch 29, loss = 0.0574617
I0807 15:36:15.439936 25679 caffe.cpp:304] Batch 30, accuracy = 1
I0807 15:36:15.439960 25679 caffe.cpp:304] Batch 30, loss = 0.0190305
I0807 15:36:15.536422 25679 caffe.cpp:304] Batch 31, accuracy = 0.8125
I0807 15:36:15.536443 25679 caffe.cpp:304] Batch 31, loss = 0.88862
I0807 15:36:15.635892 25679 caffe.cpp:304] Batch 32, accuracy = 0.875
I0807 15:36:15.635913 25679 caffe.cpp:304] Batch 32, loss = 0.699927
I0807 15:36:15.732373 25679 caffe.cpp:304] Batch 33, accuracy = 0.84375
I0807 15:36:15.732395 25679 caffe.cpp:304] Batch 33, loss = 0.44066
I0807 15:36:15.828692 25679 caffe.cpp:304] Batch 34, accuracy = 0.84375
I0807 15:36:15.828714 25679 caffe.cpp:304] Batch 34, loss = 0.375016
I0807 15:36:15.928237 25679 caffe.cpp:304] Batch 35, accuracy = 0.8125
I0807 15:36:15.928259 25679 caffe.cpp:304] Batch 35, loss = 0.665492
I0807 15:36:16.024636 25679 caffe.cpp:304] Batch 36, accuracy = 0.90625
I0807 15:36:16.024657 25679 caffe.cpp:304] Batch 36, loss = 0.352529
I0807 15:36:16.121029 25679 caffe.cpp:304] Batch 37, accuracy = 0.9375
I0807 15:36:16.121048 25679 caffe.cpp:304] Batch 37, loss = 0.347134
I0807 15:36:16.217447 25679 caffe.cpp:304] Batch 38, accuracy = 0.8125
I0807 15:36:16.217469 25679 caffe.cpp:304] Batch 38, loss = 0.492673
I0807 15:36:16.316133 25679 caffe.cpp:304] Batch 39, accuracy = 0.90625
I0807 15:36:16.316155 25679 caffe.cpp:304] Batch 39, loss = 0.307416
I0807 15:36:16.412561 25679 caffe.cpp:304] Batch 40, accuracy = 0.9375
I0807 15:36:16.412583 25679 caffe.cpp:304] Batch 40, loss = 0.295245
I0807 15:36:16.512082 25679 caffe.cpp:304] Batch 41, accuracy = 0.90625
I0807 15:36:16.512104 25679 caffe.cpp:304] Batch 41, loss = 0.305956
I0807 15:36:16.605499 25679 caffe.cpp:304] Batch 42, accuracy = 0.8125
I0807 15:36:16.605521 25679 caffe.cpp:304] Batch 42, loss = 0.841613
I0807 15:36:16.701957 25679 caffe.cpp:304] Batch 43, accuracy = 0.84375
I0807 15:36:16.701977 25679 caffe.cpp:304] Batch 43, loss = 0.723797
I0807 15:36:16.801393 25679 caffe.cpp:304] Batch 44, accuracy = 0.90625
I0807 15:36:16.801416 25679 caffe.cpp:304] Batch 44, loss = 0.416712
I0807 15:36:16.900898 25679 caffe.cpp:304] Batch 45, accuracy = 0.875
I0807 15:36:16.900920 25679 caffe.cpp:304] Batch 45, loss = 0.976521
I0807 15:36:17.000429 25679 caffe.cpp:304] Batch 46, accuracy = 0.875
I0807 15:36:17.000452 25679 caffe.cpp:304] Batch 46, loss = 0.656047
I0807 15:36:17.100004 25679 caffe.cpp:304] Batch 47, accuracy = 0.90625
I0807 15:36:17.100026 25679 caffe.cpp:304] Batch 47, loss = 0.708429
I0807 15:36:17.196377 25679 caffe.cpp:304] Batch 48, accuracy = 0.84375
I0807 15:36:17.196398 25679 caffe.cpp:304] Batch 48, loss = 0.6415
I0807 15:36:17.292794 25679 caffe.cpp:304] Batch 49, accuracy = 0.8125
I0807 15:36:17.292819 25679 caffe.cpp:304] Batch 49, loss = 0.498396
I0807 15:36:17.389282 25679 caffe.cpp:304] Batch 50, accuracy = 0.8125
I0807 15:36:17.389304 25679 caffe.cpp:304] Batch 50, loss = 1.10238
I0807 15:36:17.485769 25679 caffe.cpp:304] Batch 51, accuracy = 0.9375
I0807 15:36:17.485790 25679 caffe.cpp:304] Batch 51, loss = 0.266142
I0807 15:36:17.585302 25679 caffe.cpp:304] Batch 52, accuracy = 0.96875
I0807 15:36:17.585325 25679 caffe.cpp:304] Batch 52, loss = 0.114227
I0807 15:36:17.684916 25679 caffe.cpp:304] Batch 53, accuracy = 0.84375
I0807 15:36:17.684937 25679 caffe.cpp:304] Batch 53, loss = 0.668424
I0807 15:36:17.781391 25679 caffe.cpp:304] Batch 54, accuracy = 0.9375
I0807 15:36:17.781412 25679 caffe.cpp:304] Batch 54, loss = 0.364694
I0807 15:36:17.877892 25679 caffe.cpp:304] Batch 55, accuracy = 0.90625
I0807 15:36:17.877914 25679 caffe.cpp:304] Batch 55, loss = 0.387728
I0807 15:36:17.971454 25679 caffe.cpp:304] Batch 56, accuracy = 0.90625
I0807 15:36:17.971477 25679 caffe.cpp:304] Batch 56, loss = 0.314489
I0807 15:36:18.070955 25679 caffe.cpp:304] Batch 57, accuracy = 0.84375
I0807 15:36:18.070977 25679 caffe.cpp:304] Batch 57, loss = 0.587865
I0807 15:36:18.167388 25679 caffe.cpp:304] Batch 58, accuracy = 0.8125
I0807 15:36:18.167408 25679 caffe.cpp:304] Batch 58, loss = 0.677609
I0807 15:36:18.266968 25679 caffe.cpp:304] Batch 59, accuracy = 0.875
I0807 15:36:18.266989 25679 caffe.cpp:304] Batch 59, loss = 0.583163
I0807 15:36:18.360371 25679 caffe.cpp:304] Batch 60, accuracy = 0.84375
I0807 15:36:18.360394 25679 caffe.cpp:304] Batch 60, loss = 0.70752
I0807 15:36:18.456815 25679 caffe.cpp:304] Batch 61, accuracy = 0.90625
I0807 15:36:18.456842 25679 caffe.cpp:304] Batch 61, loss = 0.163837
I0807 15:36:18.553259 25679 caffe.cpp:304] Batch 62, accuracy = 0.84375
I0807 15:36:18.553287 25679 caffe.cpp:304] Batch 62, loss = 0.463407
I0807 15:36:18.726877 25679 caffe.cpp:304] Batch 63, accuracy = 0.875
I0807 15:36:18.726903 25679 caffe.cpp:304] Batch 63, loss = 0.820735
I0807 15:36:18.820329 25679 caffe.cpp:304] Batch 64, accuracy = 0.8125
I0807 15:36:18.820353 25679 caffe.cpp:304] Batch 64, loss = 0.546106
I0807 15:36:18.919786 25679 caffe.cpp:304] Batch 65, accuracy = 0.9375
I0807 15:36:18.919824 25679 caffe.cpp:304] Batch 65, loss = 0.116822
I0807 15:36:19.019352 25679 caffe.cpp:304] Batch 66, accuracy = 0.875
I0807 15:36:19.019376 25679 caffe.cpp:304] Batch 66, loss = 0.550366
I0807 15:36:19.118868 25679 caffe.cpp:304] Batch 67, accuracy = 0.90625
I0807 15:36:19.118891 25679 caffe.cpp:304] Batch 67, loss = 0.361698
I0807 15:36:19.218401 25679 caffe.cpp:304] Batch 68, accuracy = 0.96875
I0807 15:36:19.218425 25679 caffe.cpp:304] Batch 68, loss = 0.295062
I0807 15:36:19.314918 25679 caffe.cpp:304] Batch 69, accuracy = 0.9375
I0807 15:36:19.314944 25679 caffe.cpp:304] Batch 69, loss = 0.230583
I0807 15:36:19.411262 25679 caffe.cpp:304] Batch 70, accuracy = 0.90625
I0807 15:36:19.411284 25679 caffe.cpp:304] Batch 70, loss = 0.256
I0807 15:36:19.508831 25679 caffe.cpp:304] Batch 71, accuracy = 0.78125
I0807 15:36:19.508853 25679 caffe.cpp:304] Batch 71, loss = 1.32019
I0807 15:36:19.606478 25679 caffe.cpp:304] Batch 72, accuracy = 0.90625
I0807 15:36:19.606501 25679 caffe.cpp:304] Batch 72, loss = 0.164936
I0807 15:36:19.706044 25679 caffe.cpp:304] Batch 73, accuracy = 0.9375
I0807 15:36:19.706068 25679 caffe.cpp:304] Batch 73, loss = 0.280465
I0807 15:36:19.805613 25679 caffe.cpp:304] Batch 74, accuracy = 0.875
I0807 15:36:19.805634 25679 caffe.cpp:304] Batch 74, loss = 0.636024
I0807 15:36:19.902696 25679 caffe.cpp:304] Batch 75, accuracy = 0.84375
I0807 15:36:19.902717 25679 caffe.cpp:304] Batch 75, loss = 0.952264
I0807 15:36:20.000222 25679 caffe.cpp:304] Batch 76, accuracy = 0.90625
I0807 15:36:20.000244 25679 caffe.cpp:304] Batch 76, loss = 0.306696
I0807 15:36:20.000249 25679 caffe.cpp:309] Loss: 0.502515
I0807 15:36:20.000255 25679 caffe.cpp:321] accuracy = 0.880682
I0807 15:36:20.000262 25679 caffe.cpp:321] loss = 0.502515 (* 1 = 0.502515 loss)
